{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAYAAADuMJi0AAAGR0lEQVR42rVZ21IbRxBtCbQrkIR2dQVjsLmDLBsET3nTQ8ouYRkQVf6e/E9+Im958qMfkgoXAaKSSj6C9Jnd2R2NeiRSRaZqitVOT5+Z6dNnWoKGlN94JFp8Ipofkb/7SOXjGyp8wF+z35K3f0uUp/GW4XfLQ8v2gefj3ZCCzojoNfue+43o1Q3l3xB/yA3JO7jnF2pCLnI+pNyx/qw7L+SQ7T2N9p2f8c60QcfcK6KGXsAd+ZvA4LlZYuSSAoOhMs5vwJkEGDlbPMaJoA+FcQ0IH38QLWkbAFLkOOhoMF5tU6/eBRhNjro0ZgKiPRAt3FLhCO/vqdgmNTm32LkmKpvBmQY4q5uAaAgbwDBG2BVv3bfI8KKAMWj2kfw9+pkZREIbEql4ST1x7hgHIANkbJ//MF8mAH/ilTCJ2tIi4ASr1IC3VNqXHKOxjy34mgoImnOQtx1g81fkqTiMOBVGcTogNhiT5iBHET8R8C+iApJUmgim3SQAXhsLQz7ee2G8gOAQNtJckBEplADiAxtX+G9NmhDl0qJKnTvyWlAMPYZnvIviGXRg6/Dh824DBXhP/tbfREXJEIvQ+aaPGjG7pvw6r3xdx+9hqb4dgZaP2XmdHO2K/B0c1+oUph6k8kShBryl/Ft0DYgjTlOieOACHFFpVyUl72T9V3cM1jUoYvxIC2vpCSys/ck70mDYuYvdvKjlMdKAUThneWVU1aAsyjv6PURDiwNsHGBZzY+JtAAgE2TFxdRHJdyIp/f+zqu09M5cDP2F08Ukkpj4YNSdX950HY2pNCCUK/Hhx5ZMBfjNSEzdsIihVzzAMdn9dz4eDYhnyQb9SSCiAryiJcQk82LiTbJ4x2FZJaUenpKnzP95WyDf4Y+QN9EFHHSeDLGdBjjKNQ5vKHf4XMA7KrY0y0GEObBOO/8e1ywuQExOHXktuQyJALEBpcEqhwtHqgiDuCK5b6i0p2MQpcckIIoh+6hYgTZtO8xlMi6O4tKCF/kOGHEg/W0UUpHW0ZoGNZ1ExZWcn7EErgwt4uj50E/sFBjXXIayWvh7WryjasxarZKssXon0zxvvkc32Q0bqbBCuZiKt9dWFysfQefeL29JYFaeztX6tePaZdz5mYx8+6Zq3Mk0wXECQxlhdzgS2wjBHju3j1RIgKyOMdNUE8X0+RAdbSapS11MRCv1SzUXmO6wGZe2SQYrv2MvCSWEv2VODE6DN7bz8ufypgQKW7uQskFTQHULLKyaEyrnlZbgOGLrV5qrn9U79jjm2HJmgkaVN98AfBub91lGPLZBqdroN5LYgjSu4zYZDDHXZOIPC691HqrWI1900I8qLzgKP4ft8DxEWigprPfrO+KcXno9gZz4jjGewWdUcpGCj0qVFuGPYbl2VturndZ2qRvlL8acDO6lF/DY/VjsFesiUK+ypJ+r/ep+cJkSQxEK4PG4WozgA75TYrDDqStE69K8/mzGEM+JXTeqvmedEElMmwCMm2SLd6bNNF9su02zEtoW6nAQtpMj5Gd7fKa//wqonF7UdtHFsVn+6hf1o7AfriPH7M6EeIUEF5zKVxXbYo7kS/OEtOqDYZKPoBsETIixn0uYrasThmzDkhdKPkz2EnaX0HdQbIgr59vAdGYDqjHrxkjS7WOxkTD8sqEqhiwcJETgBYigrBqF08KyDaje9SZ/I1A7MzaTzMGDEulPtZUkuKcyIRAjxEJPVrnVlb/9wkfij31D/pQt1IN+iL8bGJcstBIO7Y5VI/cwDqURbXhMuJxBqD0KLoK3esWFs0Jz5i5ZvJUAfFJMFb9XmGIOnzGpijpcWYCaMqXSQWp8EnCABepQ0Elyi4wfKfsw78ikIqif1pe1AGPlLmojl1SKxHHXp1L+Ut7AmDQHvhI5xHGi4EooO2BR7k78PEkJOdL7cAxQUZ/Tyclu9gnfwGgOmm2lNHGNmZXsq4Pqgc1EG1ATrvKl8s4R9ywwnqulGUnaRLVhxy8v3ieUwy2hbooT68uscW++DCDH0WSzuoyN2D4LUJ/tLECbcSKznwMIFs0ChF4mRTCnQbIIfk4SHJo6A9BMuTnXTs3Ku/KxsgZWqzuSe+Os8cEUfnMBY6UF5gi3SUbd5K7vDjq5WW0UENJlRsWn4sy21Er/E/AvPQSFHy1p4fgAAAAASUVORK5CYII=');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import seaborn as sns\r\n",
    "import pickle\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, mean_squared_error\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys \r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入数据\r\n",
    "train_data = pd.read_csv('./data/data119778/train.csv', index_col= 'id')\r\n",
    "testA_data = pd.read_csv('./data/data119778/testA.csv', index_col= 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800000 entries, 0 to 799999\n",
      "Data columns (total 46 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   loanAmnt            800000 non-null  float64\n",
      " 1   term                800000 non-null  int64  \n",
      " 2   interestRate        800000 non-null  float64\n",
      " 3   installment         800000 non-null  float64\n",
      " 4   grade               800000 non-null  object \n",
      " 5   subGrade            800000 non-null  object \n",
      " 6   employmentTitle     799999 non-null  float64\n",
      " 7   employmentLength    753201 non-null  object \n",
      " 8   homeOwnership       800000 non-null  int64  \n",
      " 9   annualIncome        800000 non-null  float64\n",
      " 10  verificationStatus  800000 non-null  int64  \n",
      " 11  issueDate           800000 non-null  object \n",
      " 12  isDefault           800000 non-null  int64  \n",
      " 13  purpose             800000 non-null  int64  \n",
      " 14  postCode            799999 non-null  float64\n",
      " 15  regionCode          800000 non-null  int64  \n",
      " 16  dti                 799761 non-null  float64\n",
      " 17  delinquency_2years  800000 non-null  float64\n",
      " 18  ficoRangeLow        800000 non-null  float64\n",
      " 19  ficoRangeHigh       800000 non-null  float64\n",
      " 20  openAcc             800000 non-null  float64\n",
      " 21  pubRec              800000 non-null  float64\n",
      " 22  pubRecBankruptcies  799595 non-null  float64\n",
      " 23  revolBal            800000 non-null  float64\n",
      " 24  revolUtil           799469 non-null  float64\n",
      " 25  totalAcc            800000 non-null  float64\n",
      " 26  initialListStatus   800000 non-null  int64  \n",
      " 27  applicationType     800000 non-null  int64  \n",
      " 28  earliesCreditLine   800000 non-null  object \n",
      " 29  title               799999 non-null  float64\n",
      " 30  policyCode          800000 non-null  float64\n",
      " 31  n0                  759730 non-null  float64\n",
      " 32  n1                  759730 non-null  float64\n",
      " 33  n2                  759730 non-null  float64\n",
      " 34  n3                  759730 non-null  float64\n",
      " 35  n4                  766761 non-null  float64\n",
      " 36  n5                  759730 non-null  float64\n",
      " 37  n6                  759730 non-null  float64\n",
      " 38  n7                  759730 non-null  float64\n",
      " 39  n8                  759729 non-null  float64\n",
      " 40  n9                  759730 non-null  float64\n",
      " 41  n10                 766761 non-null  float64\n",
      " 42  n11                 730248 non-null  float64\n",
      " 43  n12                 759730 non-null  float64\n",
      " 44  n13                 759730 non-null  float64\n",
      " 45  n14                 759730 non-null  float64\n",
      "dtypes: float64(33), int64(8), object(5)\n",
      "memory usage: 286.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train[train['isDefault'] == 1][['employmentLength']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_data.copy()\r\n",
    "testA = testA_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train.describe(percentiles=[0.4, 0.6, 0.8, 0.9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loanAmnt</th>\n",
       "      <td>35000</td>\n",
       "      <td>18000</td>\n",
       "      <td>12000</td>\n",
       "      <td>11000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interestRate</th>\n",
       "      <td>19.52</td>\n",
       "      <td>18.49</td>\n",
       "      <td>16.99</td>\n",
       "      <td>7.26</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>917.97</td>\n",
       "      <td>461.9</td>\n",
       "      <td>298.17</td>\n",
       "      <td>340.96</td>\n",
       "      <td>101.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subGrade</th>\n",
       "      <td>E2</td>\n",
       "      <td>D2</td>\n",
       "      <td>D3</td>\n",
       "      <td>A4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentTitle</th>\n",
       "      <td>320</td>\n",
       "      <td>219843</td>\n",
       "      <td>31698</td>\n",
       "      <td>46854</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentLength</th>\n",
       "      <td>2 years</td>\n",
       "      <td>5 years</td>\n",
       "      <td>8 years</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homeOwnership</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualIncome</th>\n",
       "      <td>110000</td>\n",
       "      <td>46000</td>\n",
       "      <td>74000</td>\n",
       "      <td>118000</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verificationStatus</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issueDate</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isDefault</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postCode</th>\n",
       "      <td>137</td>\n",
       "      <td>156</td>\n",
       "      <td>337</td>\n",
       "      <td>148</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionCode</th>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>17.05</td>\n",
       "      <td>27.83</td>\n",
       "      <td>22.77</td>\n",
       "      <td>17.21</td>\n",
       "      <td>32.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinquency_2years</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <td>730</td>\n",
       "      <td>700</td>\n",
       "      <td>675</td>\n",
       "      <td>685</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <td>734</td>\n",
       "      <td>704</td>\n",
       "      <td>679</td>\n",
       "      <td>689</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openAcc</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolBal</th>\n",
       "      <td>24178</td>\n",
       "      <td>15096</td>\n",
       "      <td>4606</td>\n",
       "      <td>9948</td>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolUtil</th>\n",
       "      <td>48.9</td>\n",
       "      <td>38.9</td>\n",
       "      <td>51.8</td>\n",
       "      <td>52.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalAcc</th>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialListStatus</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicationType</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliesCreditLine</th>\n",
       "      <td>Aug-2001</td>\n",
       "      <td>May-2002</td>\n",
       "      <td>May-2006</td>\n",
       "      <td>May-1999</td>\n",
       "      <td>Aug-1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1</td>\n",
       "      <td>1723</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policyCode</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n5</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n6</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n8</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n11</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n12</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n13</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n14</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id                           0           1           2           3           4\n",
       "loanAmnt                 35000       18000       12000       11000        3000\n",
       "term                         5           5           5           3           3\n",
       "interestRate             19.52       18.49       16.99        7.26       12.99\n",
       "installment             917.97       461.9      298.17      340.96      101.07\n",
       "grade                        E           D           D           A           C\n",
       "subGrade                    E2          D2          D3          A4          C2\n",
       "employmentTitle            320      219843       31698       46854          54\n",
       "employmentLength       2 years     5 years     8 years   10+ years         NaN\n",
       "homeOwnership                2           0           0           1           1\n",
       "annualIncome            110000       46000       74000      118000       29000\n",
       "verificationStatus           2           2           2           1           2\n",
       "issueDate           2014-07-01  2012-08-01  2015-10-01  2015-08-01  2016-03-01\n",
       "isDefault                    1           0           0           0           0\n",
       "purpose                      1           0           0           4          10\n",
       "postCode                   137         156         337         148         301\n",
       "regionCode                  32          18          14          11          21\n",
       "dti                      17.05       27.83       22.77       17.21       32.16\n",
       "delinquency_2years           0           0           0           0           0\n",
       "ficoRangeLow               730         700         675         685         690\n",
       "ficoRangeHigh              734         704         679         689         694\n",
       "openAcc                      7          13          11           9          12\n",
       "pubRec                       0           0           0           0           0\n",
       "pubRecBankruptcies           0           0           0           0           0\n",
       "revolBal                 24178       15096        4606        9948        2942\n",
       "revolUtil                 48.9        38.9        51.8        52.6          32\n",
       "totalAcc                    27          18          27          28          27\n",
       "initialListStatus            0           1           0           1           0\n",
       "applicationType              0           0           0           0           0\n",
       "earliesCreditLine     Aug-2001    May-2002    May-2006    May-1999    Aug-1977\n",
       "title                        1        1723           0           4          11\n",
       "policyCode                   1           1           1           1           1\n",
       "n0                           0         NaN           0           6           1\n",
       "n1                           2         NaN           0           4           2\n",
       "n2                           2         NaN           3           6           7\n",
       "n3                           2         NaN           3           6           7\n",
       "n4                           4          10           0           4           2\n",
       "n5                           9         NaN           0          16           4\n",
       "n6                           8         NaN          21           4           9\n",
       "n7                           4         NaN           4           7          10\n",
       "n8                          12         NaN           5          21          15\n",
       "n9                           2         NaN           3           6           7\n",
       "n10                          7          13          11           9          12\n",
       "n11                          0         NaN           0           0           0\n",
       "n12                          0         NaN           0           0           0\n",
       "n13                          0         NaN           0           0           0\n",
       "n14                          2         NaN           4           1           4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 检查共同特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_columns = []\r\n",
    "for column in train.columns:\r\n",
    "    if column in testA.columns:\r\n",
    "        common_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 46, 45)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_columns), len(train.columns), len(testA.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 列出object 类型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>issueDate</th>\n",
       "      <th>earliesCreditLine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>2 years</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>Aug-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>5 years</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>May-2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>8 years</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>May-2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>May-1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Aug-1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>7 years</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Aug-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>May-1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>Jul-2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>Jan-1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>5 years</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>Feb-2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade subGrade employmentLength   issueDate earliesCreditLine\n",
       "id                                                                  \n",
       "0          E       E2          2 years  2014-07-01          Aug-2001\n",
       "1          D       D2          5 years  2012-08-01          May-2002\n",
       "2          D       D3          8 years  2015-10-01          May-2006\n",
       "3          A       A4        10+ years  2015-08-01          May-1999\n",
       "4          C       C2              NaN  2016-03-01          Aug-1977\n",
       "...      ...      ...              ...         ...               ...\n",
       "799995     C       C4          7 years  2016-07-01          Aug-2011\n",
       "799996     A       A4        10+ years  2013-04-01          May-1989\n",
       "799997     C       C3        10+ years  2015-10-01          Jul-2002\n",
       "799998     A       A4        10+ years  2015-02-01          Jan-1994\n",
       "799999     B       B3          5 years  2018-08-01          Feb-2002\n",
       "\n",
       "[800000 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include='O')\r\n",
    "# testA.select_dtypes(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 检查数字特征的连续性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle',\n",
       "       'homeOwnership', 'annualIncome', 'verificationStatus', 'isDefault',\n",
       "       'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years',\n",
       "       'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec',\n",
       "       'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc',\n",
       "       'initialListStatus', 'applicationType', 'title', 'policyCode', 'n0',\n",
       "       'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11',\n",
       "       'n12', 'n13', 'n14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train['n1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_series_fea=[]\r\n",
    "numerical_noseries_fea=[]\r\n",
    "\r\n",
    "for fea in train.select_dtypes(exclude='O').columns:\r\n",
    "    numerical_series_fea.append(fea) if train[fea].unique().size >= 10 else numerical_noseries_fea.append(fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['loanAmnt',\n",
       "  'interestRate',\n",
       "  'installment',\n",
       "  'employmentTitle',\n",
       "  'annualIncome',\n",
       "  'purpose',\n",
       "  'postCode',\n",
       "  'regionCode',\n",
       "  'dti',\n",
       "  'delinquency_2years',\n",
       "  'ficoRangeLow',\n",
       "  'ficoRangeHigh',\n",
       "  'openAcc',\n",
       "  'pubRec',\n",
       "  'pubRecBankruptcies',\n",
       "  'revolBal',\n",
       "  'revolUtil',\n",
       "  'totalAcc',\n",
       "  'title',\n",
       "  'n0',\n",
       "  'n1',\n",
       "  'n2',\n",
       "  'n3',\n",
       "  'n4',\n",
       "  'n5',\n",
       "  'n6',\n",
       "  'n7',\n",
       "  'n8',\n",
       "  'n9',\n",
       "  'n10',\n",
       "  'n13',\n",
       "  'n14'],\n",
       " ['term',\n",
       "  'homeOwnership',\n",
       "  'verificationStatus',\n",
       "  'isDefault',\n",
       "  'initialListStatus',\n",
       "  'applicationType',\n",
       "  'policyCode',\n",
       "  'n11',\n",
       "  'n12'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_series_fea,numerical_noseries_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testA_numerical_series_fea=[]\r\n",
    "testA_numerical_noseries_fea=[]\r\n",
    "\r\n",
    "for fea in testA.select_dtypes(exclude='O').columns:\r\n",
    "    testA_numerical_series_fea.append(fea) if testA[fea].unique().size >= 10 else testA_numerical_noseries_fea.append(fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['loanAmnt',\n",
       "  'interestRate',\n",
       "  'installment',\n",
       "  'employmentTitle',\n",
       "  'annualIncome',\n",
       "  'purpose',\n",
       "  'postCode',\n",
       "  'regionCode',\n",
       "  'dti',\n",
       "  'delinquency_2years',\n",
       "  'ficoRangeLow',\n",
       "  'ficoRangeHigh',\n",
       "  'openAcc',\n",
       "  'pubRec',\n",
       "  'pubRecBankruptcies',\n",
       "  'revolBal',\n",
       "  'revolUtil',\n",
       "  'totalAcc',\n",
       "  'title',\n",
       "  'n0',\n",
       "  'n1',\n",
       "  'n2',\n",
       "  'n3',\n",
       "  'n4',\n",
       "  'n5',\n",
       "  'n6',\n",
       "  'n7',\n",
       "  'n8',\n",
       "  'n9',\n",
       "  'n10',\n",
       "  'n13',\n",
       "  'n14'],\n",
       " ['term',\n",
       "  'homeOwnership',\n",
       "  'verificationStatus',\n",
       "  'initialListStatus',\n",
       "  'applicationType',\n",
       "  'policyCode',\n",
       "  'n11',\n",
       "  'n12'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testA_numerical_series_fea, testA_numerical_noseries_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 检查空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include_nan_fea = []\r\n",
    "\r\n",
    "for fea in train.columns:\r\n",
    "    percent_of_null = train[fea].isnull().sum()/train.shape[0] * 100\r\n",
    "    if percent_of_null > 0 :\r\n",
    "        include_nan_fea.append((fea, percent_of_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('employmentTitle', 0.000125),\n",
       " ('employmentLength', 5.849875),\n",
       " ('postCode', 0.000125),\n",
       " ('dti', 0.029875000000000002),\n",
       " ('pubRecBankruptcies', 0.050624999999999996),\n",
       " ('revolUtil', 0.06637499999999999),\n",
       " ('title', 0.000125),\n",
       " ('n0', 5.03375),\n",
       " ('n1', 5.03375),\n",
       " ('n2', 5.03375),\n",
       " ('n3', 5.03375),\n",
       " ('n4', 4.1548750000000005),\n",
       " ('n5', 5.03375),\n",
       " ('n6', 5.03375),\n",
       " ('n7', 5.03375),\n",
       " ('n8', 5.033875),\n",
       " ('n9', 5.03375),\n",
       " ('n10', 4.1548750000000005),\n",
       " ('n11', 8.719000000000001),\n",
       " ('n12', 5.03375),\n",
       " ('n13', 5.03375),\n",
       " ('n14', 5.03375)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_nan_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Unique_values</th>\n",
       "      <th>Percentage of missing values</th>\n",
       "      <th>Percentage of values in the biggest category</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>n11</td>\n",
       "      <td>5</td>\n",
       "      <td>8.719000</td>\n",
       "      <td>91.210250</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>employmentLength</td>\n",
       "      <td>11</td>\n",
       "      <td>5.849875</td>\n",
       "      <td>32.844125</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>n8</td>\n",
       "      <td>102</td>\n",
       "      <td>5.033875</td>\n",
       "      <td>5.601000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>n14</td>\n",
       "      <td>31</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>23.437625</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>n3</td>\n",
       "      <td>50</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>14.651375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>n13</td>\n",
       "      <td>28</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>89.516375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>n12</td>\n",
       "      <td>5</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>94.664375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>n0</td>\n",
       "      <td>39</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>72.428375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n1</td>\n",
       "      <td>33</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>20.376000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>n9</td>\n",
       "      <td>44</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>14.766750</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>n7</td>\n",
       "      <td>70</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>10.416375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>n6</td>\n",
       "      <td>107</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>8.086500</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>n5</td>\n",
       "      <td>65</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>9.572000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>n2</td>\n",
       "      <td>50</td>\n",
       "      <td>5.033750</td>\n",
       "      <td>14.651375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>n4</td>\n",
       "      <td>46</td>\n",
       "      <td>4.154875</td>\n",
       "      <td>16.816125</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>n10</td>\n",
       "      <td>76</td>\n",
       "      <td>4.154875</td>\n",
       "      <td>8.502875</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>revolUtil</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.521250</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pubRecBankruptcies</td>\n",
       "      <td>11</td>\n",
       "      <td>0.050625</td>\n",
       "      <td>87.509500</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dti</td>\n",
       "      <td>6321</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>0.074125</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>postCode</td>\n",
       "      <td>932</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.119500</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>employmentTitle</td>\n",
       "      <td>248683</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>6.393625</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>title</td>\n",
       "      <td>39644</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>49.166750</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>initialListStatus</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.304750</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Unique_values  Percentage of missing values  \\\n",
       "42                 n11              5                      8.719000   \n",
       "7     employmentLength             11                      5.849875   \n",
       "39                  n8            102                      5.033875   \n",
       "45                 n14             31                      5.033750   \n",
       "34                  n3             50                      5.033750   \n",
       "44                 n13             28                      5.033750   \n",
       "43                 n12              5                      5.033750   \n",
       "31                  n0             39                      5.033750   \n",
       "32                  n1             33                      5.033750   \n",
       "40                  n9             44                      5.033750   \n",
       "38                  n7             70                      5.033750   \n",
       "37                  n6            107                      5.033750   \n",
       "36                  n5             65                      5.033750   \n",
       "33                  n2             50                      5.033750   \n",
       "35                  n4             46                      4.154875   \n",
       "41                 n10             76                      4.154875   \n",
       "24           revolUtil           1286                      0.066375   \n",
       "22  pubRecBankruptcies             11                      0.050625   \n",
       "16                 dti           6321                      0.029875   \n",
       "14            postCode            932                      0.000125   \n",
       "6      employmentTitle         248683                      0.000125   \n",
       "29               title          39644                      0.000125   \n",
       "26   initialListStatus              2                      0.000000   \n",
       "\n",
       "    Percentage of values in the biggest category     type  \n",
       "42                                     91.210250  float64  \n",
       "7                                      32.844125   object  \n",
       "39                                      5.601000  float64  \n",
       "45                                     23.437625  float64  \n",
       "34                                     14.651375  float64  \n",
       "44                                     89.516375  float64  \n",
       "43                                     94.664375  float64  \n",
       "31                                     72.428375  float64  \n",
       "32                                     20.376000  float64  \n",
       "40                                     14.766750  float64  \n",
       "38                                     10.416375  float64  \n",
       "37                                      8.086500  float64  \n",
       "36                                      9.572000  float64  \n",
       "33                                     14.651375  float64  \n",
       "35                                     16.816125  float64  \n",
       "41                                      8.502875  float64  \n",
       "24                                      0.521250  float64  \n",
       "22                                     87.509500  float64  \n",
       "16                                      0.074125  float64  \n",
       "14                                      1.119500  float64  \n",
       "6                                       6.393625  float64  \n",
       "29                                     49.166750  float64  \n",
       "26                                     58.304750    int64  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\r\n",
    "for col in train.columns:\r\n",
    "    stats.append((col, train[col].nunique(), train[col].isnull().sum() * 100 / train.shape[0], train[col].value_counts(normalize=True, dropna=False).values[0] * 100, train[col].dtype))\r\n",
    "    \r\n",
    "stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique_values', 'Percentage of missing values', 'Percentage of values in the biggest category', 'type'])\r\n",
    "stats_df.sort_values('Percentage of missing values', ascending=False)[:23]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testA_include_nan_fea = []\r\n",
    "\r\n",
    "for fea in testA.columns:\r\n",
    "    percent_of_null = testA[fea].isnull().sum()/testA.shape[0] * 100\r\n",
    "    if percent_of_null > 0 :\r\n",
    "        testA_include_nan_fea.append((fea, percent_of_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dti', 0.0305),\n",
       " ('employmentLength', 5.8709999999999996),\n",
       " ('n0', 5.0555),\n",
       " ('n1', 5.0555),\n",
       " ('n10', 4.197),\n",
       " ('n11', 8.7875),\n",
       " ('n12', 5.0555),\n",
       " ('n13', 5.0555),\n",
       " ('n14', 5.0555),\n",
       " ('n2', 5.0555),\n",
       " ('n3', 5.0555),\n",
       " ('n4', 4.197),\n",
       " ('n5', 5.0555),\n",
       " ('n6', 5.0555),\n",
       " ('n7', 5.0555),\n",
       " ('n8', 5.0555),\n",
       " ('n9', 5.0555),\n",
       " ('pubRecBankruptcies', 0.058),\n",
       " ('revolUtil', 0.0635)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testA_include_nan_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 检查分布一致性、异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train['Source'] = 'Train'\r\n",
    "# testA['Source'] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge_data = pd.concat((train.join(pd.DataFrame(['Train' for i in range(len(train))], index=train.index, columns=['Source']), how='left'),\r\n",
    "                        testA.join(pd.DataFrame(['Test' for i in range(len(testA))], index=testA.index, columns=['Source']), how='left')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_melted = pd.melt(merge_data, id_vars= ['Source'],\r\n",
    "                    # value_vars=testA_numerical_series_fea\r\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train</td>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train</td>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999995</th>\n",
       "      <td>Test</td>\n",
       "      <td>n14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999996</th>\n",
       "      <td>Test</td>\n",
       "      <td>n14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999997</th>\n",
       "      <td>Test</td>\n",
       "      <td>n14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999998</th>\n",
       "      <td>Test</td>\n",
       "      <td>n14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999999</th>\n",
       "      <td>Test</td>\n",
       "      <td>n14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Source  variable  value\n",
       "0         Train  loanAmnt  35000\n",
       "1         Train  loanAmnt  18000\n",
       "2         Train  loanAmnt  12000\n",
       "3         Train  loanAmnt  11000\n",
       "4         Train  loanAmnt   3000\n",
       "...         ...       ...    ...\n",
       "45999995   Test       n14      4\n",
       "45999996   Test       n14      0\n",
       "45999997   Test       n14      0\n",
       "45999998   Test       n14      2\n",
       "45999999   Test       n14      0\n",
       "\n",
       "[46000000 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#画出各特征的分布图\r\n",
    "\r\n",
    "g = sns.FacetGrid(df_melted, hue = 'Source', col='variable', col_wrap= 2, sharex=False, sharey=False)\r\n",
    "g = g.map(sns.distplot, \"value\")\r\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 检查特征取值范围、异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_col_val = pd.DataFrame()\r\n",
    "for col in merge_data.columns:\r\n",
    "    col_val_cnt = merge_data[col].value_counts()\r\n",
    "    df_col_val = df_col_val.append(pd.DataFrame({'fea_name': col, 'value':list(col_val_cnt.index), 'cnts':col_val_cnt.values}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_col_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_col_val.to_csv('./work/features/df_col_val.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "异常值：\n",
    "1、训练集有两条记录 dti = -1：merge_data[merge_data['dti'] == -1].T；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>dti</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258110</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356894</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.159574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loanAmnt  annualIncome  dti         0\n",
       "id                                           \n",
       "258110   17000.0       75000.0 -1.0  0.226667\n",
       "356894   15000.0       94000.0 -1.0  0.159574"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge_data[merge_data['dti']== -1].T\r\n",
    "merge_data[['loanAmnt', 'annualIncome', 'dti']].join(pd.DataFrame(merge_data['loanAmnt']/merge_data['annualIncome']), how='left')[merge_data['dti']== -1]\r\n",
    "# merge_data['loanAmnt']/merge_data['annualIncome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 处理异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#处理dti = -1 的异常数据\r\n",
    "mean_dti = train[np.array(train['dti'] >= 0) * np.array(train['isDefault'] == 0)]['dti'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[train['dti'] < 0, 'dti'] = mean_dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "258110    17.811673\n",
       "356894    17.811673\n",
       "Name: dti, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[[258110, 356894]]['dti']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 填充空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train[testA_numerical_series_fea]\r\n",
    "# train[['regionCode']].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 处理连续性特征的空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_fea = {'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'initialListStatus', 'applicationType', 'policyCode', 'title'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_fea = set(train.select_dtypes(exclude=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_fea = list(numerical_fea - categorical_fea - {'isDefault'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[numerical_fea] = train[numerical_fea].fillna(train[numerical_fea].median())\r\n",
    "testA[numerical_fea] = testA[numerical_fea].fillna(testA[numerical_fea].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 处理分类特征的空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grade', 'subGrade', 'employmentLength', 'issueDate',\n",
       "       'earliesCreditLine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['issueDate',\n",
       " 'earliesCreditLine',\n",
       " 'employmentLength',\n",
       " 'title',\n",
       " 'policyCode',\n",
       " 'verificationStatus',\n",
       " 'initialListStatus',\n",
       " 'employmentTitle',\n",
       " 'grade',\n",
       " 'regionCode',\n",
       " 'postCode',\n",
       " 'purpose',\n",
       " 'homeOwnership',\n",
       " 'subGrade',\n",
       " 'applicationType']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(train.select_dtypes(include=['object']).columns).union(categorical_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purpose                   0\n",
       "applicationType           0\n",
       "earliesCreditLine         0\n",
       "employmentTitle           1\n",
       "regionCode                0\n",
       "homeOwnership             0\n",
       "employmentLength      46799\n",
       "initialListStatus         0\n",
       "subGrade                  0\n",
       "grade                     0\n",
       "policyCode                0\n",
       "title                     1\n",
       "verificationStatus        0\n",
       "postCode                  1\n",
       "issueDate                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[list(set(train.select_dtypes(include=['object']).columns).union(categorical_fea))].isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 处理employmentLength 的空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\r\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试随机森林拟合缺失值的效果，效果不理想\r\n",
    "\r\n",
    "def test_missing(df,estimate_list,miss_col):\r\n",
    "    \"\"\"df要处理的数据帧，estimate_list用来估计缺失值的字段列表,miss_col缺失字段名称;会直接在原来的数据帧上修改\"\"\"\r\n",
    "    df = df.copy()\r\n",
    "    col_list=estimate_list\r\n",
    "    col_list.append(miss_col)   \r\n",
    "    process_df = df.loc[:,col_list]\r\n",
    "\r\n",
    "    object_cols = list(process_df.select_dtypes(include='O').columns)\r\n",
    "    object_cols.remove(miss_col)\r\n",
    "\r\n",
    "    class_le= LabelEncoder()\r\n",
    "    for i in object_cols:\r\n",
    "        process_df.loc[:,i]=class_le.fit_transform(process_df.loc[:,i])\r\n",
    "        # process_df.loc[:,i]=process_df.loc[:,i].astype(int)\r\n",
    "    # 分成已知该特征和未知该特征两部分\r\n",
    "    known=process_df[process_df[miss_col].notnull()]\r\n",
    "    known.iloc[:, -1]=class_le.fit_transform(known.iloc[:, -1])\r\n",
    "    # unknown = process_df[process_df[miss_col].isnull()].values\r\n",
    "    # X为特征属性值\r\n",
    "    X = known.iloc[:, :-1]\r\n",
    "\r\n",
    "    # y为结果标签值\r\n",
    "    y = known.iloc[:, -1:-2:-1]\r\n",
    "\r\n",
    "    X = X.fillna(X.mean())\r\n",
    "\r\n",
    "    X_train,X_eval,y_train,y_eval = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\r\n",
    "\r\n",
    "    # fit到RandomForestRegressor之中\r\n",
    "    rfr = ensemble.RandomForestRegressor(random_state=1, n_estimators=20,max_depth=4,n_jobs=-1)\r\n",
    "    rfr.fit(X_train, y_train)\r\n",
    "    # 用得到的模型进行验证\r\n",
    "    y_pred = rfr.predict(X_eval)#.round(0).astype(int)\r\n",
    "\r\n",
    "    # for_class_pred = y_pred.astype(int)\r\n",
    "    # for_class_real = y_eval.astype(int)\r\n",
    "\r\n",
    "    # print(accuracy_score(for_class_real, for_class_pred))\r\n",
    "\r\n",
    "\r\n",
    "    # print('y_pred:',type(y_pred))\r\n",
    "    # print('y_pred:',y_pred.shape)\r\n",
    "\r\n",
    "    return y_pred, y_eval\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试lgbm拟合缺失值的效果，测试结果比randomForest好\r\n",
    "\r\n",
    "def set_missing(df,estimate_list,miss_col):\r\n",
    "    \"\"\"df要处理的数据帧，estimate_list用来估计缺失值的字段列表,miss_col缺失字段名称;会直接在原来的数据帧上修改\"\"\"\r\n",
    "    df = df.copy()\r\n",
    "    col_list=estimate_list\r\n",
    "    col_list.append(miss_col)   \r\n",
    "    process_df = df.loc[:,col_list]\r\n",
    "\r\n",
    "    object_cols = list(process_df.select_dtypes(include='O').columns)\r\n",
    "    object_cols.remove(miss_col)\r\n",
    "\r\n",
    "    class_le= LabelEncoder()\r\n",
    "    for i in object_cols:\r\n",
    "        process_df.loc[:,i]=class_le.fit_transform(process_df.loc[:,i])\r\n",
    "        # process_df.loc[:,i]=process_df.loc[:,i].astype(int)\r\n",
    "    # 分成已知该特征和未知该特征两部分\r\n",
    "    known = process_df[process_df[miss_col].notnull()]\r\n",
    "    known.iloc[:, -1] = class_le.fit_transform(known.iloc[:, -1])\r\n",
    "\r\n",
    "    #需要填充的数据：\r\n",
    "    unknown = process_df[process_df[miss_col].isnull()]\r\n",
    "    \r\n",
    "    # X为特征属性值\r\n",
    "    X = known.iloc[:, :-1]\r\n",
    "\r\n",
    "    # y为结果标签值\r\n",
    "    y = known.iloc[:, -1:-2:-1]\r\n",
    "\r\n",
    "    X_train,X_eval,y_train,y_eval = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\r\n",
    "\r\n",
    "    # fit到LGBMClassifier之中\r\n",
    "    clf_ex = lgb.LGBMClassifier(objective='multiclass', metric = 'multi_logloss,auc_mu', \r\n",
    "                                n_estimators=500, \r\n",
    "                                max_depth=5, learning_rate=0.1)\r\n",
    "\r\n",
    "    clf_ex.fit(X_train, y_train, eval_set=(X_eval, y_eval),\r\n",
    "               early_stopping_rounds = 10)\r\n",
    "\r\n",
    "    # # 用得到的模型进行验证\r\n",
    "    # y_pred = clf_ex.predict(X_eval)#.round(0).astype(int)\r\n",
    "\r\n",
    "    # return y_pred, y_eval\r\n",
    "\r\n",
    "    # 用得到的模型进行未知特征值预测\r\n",
    "    predicted = clf_ex.predict(unknown.iloc[:, :-1])#.round(0).astype(int)\r\n",
    "    predicted = class_le.inverse_transform(predicted)\r\n",
    "\r\n",
    "    # 用得到的预测结果填补原缺失数据\r\n",
    "    df.loc[(df[miss_col].isnull()), miss_col] = predicted\r\n",
    "    return df\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimate_list = list(train.columns)\r\n",
    "estimate_list.remove('employmentLength')\r\n",
    "miss_col = 'employmentLength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试模型\r\n",
    "# y_pred, y_eval = test_missing(train, estimate_list, miss_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #检查测试结果\r\n",
    "# acc_score=accuracy_score(y_eval, y_pred.round())\r\n",
    "# mse_err=mean_squared_error(y_eval, y_pred.round())\r\n",
    "# recall=recall_score(y_eval, y_pred.round(), average='micro')\r\n",
    "# acc_score, mse_err, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's multi_logloss: 2.1101\tvalid_0's auc_mu: 0.586909\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.10192\tvalid_0's auc_mu: 0.589626\n",
      "[3]\tvalid_0's multi_logloss: 2.09546\tvalid_0's auc_mu: 0.591519\n",
      "[4]\tvalid_0's multi_logloss: 2.09012\tvalid_0's auc_mu: 0.592826\n",
      "[5]\tvalid_0's multi_logloss: 2.08572\tvalid_0's auc_mu: 0.594113\n",
      "[6]\tvalid_0's multi_logloss: 2.082\tvalid_0's auc_mu: 0.595448\n",
      "[7]\tvalid_0's multi_logloss: 2.07888\tvalid_0's auc_mu: 0.59633\n",
      "[8]\tvalid_0's multi_logloss: 2.07624\tvalid_0's auc_mu: 0.597001\n",
      "[9]\tvalid_0's multi_logloss: 2.07393\tvalid_0's auc_mu: 0.597714\n",
      "[10]\tvalid_0's multi_logloss: 2.07185\tvalid_0's auc_mu: 0.598573\n",
      "[11]\tvalid_0's multi_logloss: 2.07007\tvalid_0's auc_mu: 0.598966\n",
      "[12]\tvalid_0's multi_logloss: 2.06831\tvalid_0's auc_mu: 0.599689\n",
      "[13]\tvalid_0's multi_logloss: 2.06683\tvalid_0's auc_mu: 0.600483\n",
      "[14]\tvalid_0's multi_logloss: 2.06548\tvalid_0's auc_mu: 0.600987\n",
      "[15]\tvalid_0's multi_logloss: 2.06422\tvalid_0's auc_mu: 0.601357\n",
      "[16]\tvalid_0's multi_logloss: 2.06295\tvalid_0's auc_mu: 0.6023\n",
      "[17]\tvalid_0's multi_logloss: 2.06189\tvalid_0's auc_mu: 0.602799\n",
      "[18]\tvalid_0's multi_logloss: 2.06068\tvalid_0's auc_mu: 0.603745\n",
      "[19]\tvalid_0's multi_logloss: 2.05992\tvalid_0's auc_mu: 0.604022\n",
      "[20]\tvalid_0's multi_logloss: 2.05914\tvalid_0's auc_mu: 0.604324\n",
      "[21]\tvalid_0's multi_logloss: 2.05822\tvalid_0's auc_mu: 0.605049\n",
      "[22]\tvalid_0's multi_logloss: 2.05729\tvalid_0's auc_mu: 0.605436\n",
      "[23]\tvalid_0's multi_logloss: 2.05639\tvalid_0's auc_mu: 0.605962\n",
      "[24]\tvalid_0's multi_logloss: 2.05577\tvalid_0's auc_mu: 0.606373\n",
      "[25]\tvalid_0's multi_logloss: 2.05493\tvalid_0's auc_mu: 0.606884\n",
      "[26]\tvalid_0's multi_logloss: 2.05381\tvalid_0's auc_mu: 0.607486\n",
      "[27]\tvalid_0's multi_logloss: 2.05325\tvalid_0's auc_mu: 0.607871\n",
      "[28]\tvalid_0's multi_logloss: 2.05268\tvalid_0's auc_mu: 0.608234\n",
      "[29]\tvalid_0's multi_logloss: 2.05206\tvalid_0's auc_mu: 0.608695\n",
      "[30]\tvalid_0's multi_logloss: 2.05136\tvalid_0's auc_mu: 0.609195\n",
      "[31]\tvalid_0's multi_logloss: 2.05084\tvalid_0's auc_mu: 0.609525\n",
      "[32]\tvalid_0's multi_logloss: 2.05029\tvalid_0's auc_mu: 0.609986\n",
      "[33]\tvalid_0's multi_logloss: 2.04982\tvalid_0's auc_mu: 0.610115\n",
      "[34]\tvalid_0's multi_logloss: 2.04922\tvalid_0's auc_mu: 0.610351\n",
      "[35]\tvalid_0's multi_logloss: 2.04829\tvalid_0's auc_mu: 0.61073\n",
      "[36]\tvalid_0's multi_logloss: 2.04788\tvalid_0's auc_mu: 0.610993\n",
      "[37]\tvalid_0's multi_logloss: 2.04756\tvalid_0's auc_mu: 0.611243\n",
      "[38]\tvalid_0's multi_logloss: 2.0472\tvalid_0's auc_mu: 0.611453\n",
      "[39]\tvalid_0's multi_logloss: 2.0469\tvalid_0's auc_mu: 0.611598\n",
      "[40]\tvalid_0's multi_logloss: 2.04643\tvalid_0's auc_mu: 0.611983\n",
      "[41]\tvalid_0's multi_logloss: 2.04605\tvalid_0's auc_mu: 0.612261\n",
      "[42]\tvalid_0's multi_logloss: 2.04575\tvalid_0's auc_mu: 0.612366\n",
      "[43]\tvalid_0's multi_logloss: 2.04501\tvalid_0's auc_mu: 0.612672\n",
      "[44]\tvalid_0's multi_logloss: 2.04477\tvalid_0's auc_mu: 0.612884\n",
      "[45]\tvalid_0's multi_logloss: 2.04428\tvalid_0's auc_mu: 0.613217\n",
      "[46]\tvalid_0's multi_logloss: 2.04387\tvalid_0's auc_mu: 0.613521\n",
      "[47]\tvalid_0's multi_logloss: 2.04343\tvalid_0's auc_mu: 0.613827\n",
      "[48]\tvalid_0's multi_logloss: 2.04319\tvalid_0's auc_mu: 0.613946\n",
      "[49]\tvalid_0's multi_logloss: 2.04289\tvalid_0's auc_mu: 0.61405\n",
      "[50]\tvalid_0's multi_logloss: 2.04254\tvalid_0's auc_mu: 0.614202\n",
      "[51]\tvalid_0's multi_logloss: 2.04223\tvalid_0's auc_mu: 0.614347\n",
      "[52]\tvalid_0's multi_logloss: 2.04192\tvalid_0's auc_mu: 0.61459\n",
      "[53]\tvalid_0's multi_logloss: 2.04165\tvalid_0's auc_mu: 0.614635\n",
      "[54]\tvalid_0's multi_logloss: 2.04142\tvalid_0's auc_mu: 0.61474\n",
      "[55]\tvalid_0's multi_logloss: 2.04123\tvalid_0's auc_mu: 0.614816\n",
      "[56]\tvalid_0's multi_logloss: 2.04101\tvalid_0's auc_mu: 0.614852\n",
      "[57]\tvalid_0's multi_logloss: 2.04081\tvalid_0's auc_mu: 0.614933\n",
      "[58]\tvalid_0's multi_logloss: 2.04043\tvalid_0's auc_mu: 0.615081\n",
      "[59]\tvalid_0's multi_logloss: 2.04012\tvalid_0's auc_mu: 0.615251\n",
      "[60]\tvalid_0's multi_logloss: 2.03982\tvalid_0's auc_mu: 0.615461\n",
      "[61]\tvalid_0's multi_logloss: 2.03968\tvalid_0's auc_mu: 0.615498\n",
      "[62]\tvalid_0's multi_logloss: 2.03947\tvalid_0's auc_mu: 0.615572\n",
      "[63]\tvalid_0's multi_logloss: 2.03922\tvalid_0's auc_mu: 0.615699\n",
      "[64]\tvalid_0's multi_logloss: 2.03874\tvalid_0's auc_mu: 0.615918\n",
      "[65]\tvalid_0's multi_logloss: 2.0386\tvalid_0's auc_mu: 0.61597\n",
      "[66]\tvalid_0's multi_logloss: 2.03846\tvalid_0's auc_mu: 0.616041\n",
      "[67]\tvalid_0's multi_logloss: 2.03821\tvalid_0's auc_mu: 0.616105\n",
      "[68]\tvalid_0's multi_logloss: 2.03795\tvalid_0's auc_mu: 0.616263\n",
      "[69]\tvalid_0's multi_logloss: 2.03784\tvalid_0's auc_mu: 0.616307\n",
      "[70]\tvalid_0's multi_logloss: 2.0377\tvalid_0's auc_mu: 0.616356\n",
      "[71]\tvalid_0's multi_logloss: 2.03757\tvalid_0's auc_mu: 0.616421\n",
      "[72]\tvalid_0's multi_logloss: 2.03738\tvalid_0's auc_mu: 0.616462\n",
      "[73]\tvalid_0's multi_logloss: 2.03721\tvalid_0's auc_mu: 0.616537\n",
      "[74]\tvalid_0's multi_logloss: 2.03701\tvalid_0's auc_mu: 0.61657\n",
      "[75]\tvalid_0's multi_logloss: 2.03678\tvalid_0's auc_mu: 0.616664\n",
      "[76]\tvalid_0's multi_logloss: 2.03647\tvalid_0's auc_mu: 0.616749\n",
      "[77]\tvalid_0's multi_logloss: 2.03625\tvalid_0's auc_mu: 0.616886\n",
      "[78]\tvalid_0's multi_logloss: 2.036\tvalid_0's auc_mu: 0.616965\n",
      "[79]\tvalid_0's multi_logloss: 2.03585\tvalid_0's auc_mu: 0.617121\n",
      "[80]\tvalid_0's multi_logloss: 2.03569\tvalid_0's auc_mu: 0.617151\n",
      "[81]\tvalid_0's multi_logloss: 2.03556\tvalid_0's auc_mu: 0.617192\n",
      "[82]\tvalid_0's multi_logloss: 2.03547\tvalid_0's auc_mu: 0.617248\n",
      "[83]\tvalid_0's multi_logloss: 2.03527\tvalid_0's auc_mu: 0.617431\n",
      "[84]\tvalid_0's multi_logloss: 2.03521\tvalid_0's auc_mu: 0.617409\n",
      "[85]\tvalid_0's multi_logloss: 2.03513\tvalid_0's auc_mu: 0.617465\n",
      "[86]\tvalid_0's multi_logloss: 2.03488\tvalid_0's auc_mu: 0.617562\n",
      "[87]\tvalid_0's multi_logloss: 2.0347\tvalid_0's auc_mu: 0.617705\n",
      "[88]\tvalid_0's multi_logloss: 2.03452\tvalid_0's auc_mu: 0.617742\n",
      "[89]\tvalid_0's multi_logloss: 2.0344\tvalid_0's auc_mu: 0.617704\n",
      "[90]\tvalid_0's multi_logloss: 2.03421\tvalid_0's auc_mu: 0.617808\n",
      "[91]\tvalid_0's multi_logloss: 2.03405\tvalid_0's auc_mu: 0.617794\n",
      "[92]\tvalid_0's multi_logloss: 2.0339\tvalid_0's auc_mu: 0.617824\n",
      "[93]\tvalid_0's multi_logloss: 2.03345\tvalid_0's auc_mu: 0.618025\n",
      "[94]\tvalid_0's multi_logloss: 2.03333\tvalid_0's auc_mu: 0.618062\n",
      "[95]\tvalid_0's multi_logloss: 2.03316\tvalid_0's auc_mu: 0.6182\n",
      "[96]\tvalid_0's multi_logloss: 2.03284\tvalid_0's auc_mu: 0.618343\n",
      "[97]\tvalid_0's multi_logloss: 2.03275\tvalid_0's auc_mu: 0.618371\n",
      "[98]\tvalid_0's multi_logloss: 2.03263\tvalid_0's auc_mu: 0.61843\n",
      "[99]\tvalid_0's multi_logloss: 2.03257\tvalid_0's auc_mu: 0.618457\n",
      "[100]\tvalid_0's multi_logloss: 2.03254\tvalid_0's auc_mu: 0.618431\n",
      "[101]\tvalid_0's multi_logloss: 2.03243\tvalid_0's auc_mu: 0.618545\n",
      "[102]\tvalid_0's multi_logloss: 2.03234\tvalid_0's auc_mu: 0.618583\n",
      "[103]\tvalid_0's multi_logloss: 2.03214\tvalid_0's auc_mu: 0.618676\n",
      "[104]\tvalid_0's multi_logloss: 2.03198\tvalid_0's auc_mu: 0.61874\n",
      "[105]\tvalid_0's multi_logloss: 2.03159\tvalid_0's auc_mu: 0.618853\n",
      "[106]\tvalid_0's multi_logloss: 2.03149\tvalid_0's auc_mu: 0.618896\n",
      "[107]\tvalid_0's multi_logloss: 2.03144\tvalid_0's auc_mu: 0.618869\n",
      "[108]\tvalid_0's multi_logloss: 2.03114\tvalid_0's auc_mu: 0.618996\n",
      "[109]\tvalid_0's multi_logloss: 2.03105\tvalid_0's auc_mu: 0.619041\n",
      "[110]\tvalid_0's multi_logloss: 2.03102\tvalid_0's auc_mu: 0.619042\n",
      "[111]\tvalid_0's multi_logloss: 2.03096\tvalid_0's auc_mu: 0.619041\n",
      "[112]\tvalid_0's multi_logloss: 2.03086\tvalid_0's auc_mu: 0.619074\n",
      "[113]\tvalid_0's multi_logloss: 2.03078\tvalid_0's auc_mu: 0.619159\n",
      "[114]\tvalid_0's multi_logloss: 2.03046\tvalid_0's auc_mu: 0.619214\n",
      "[115]\tvalid_0's multi_logloss: 2.03039\tvalid_0's auc_mu: 0.619276\n",
      "[116]\tvalid_0's multi_logloss: 2.03035\tvalid_0's auc_mu: 0.619236\n",
      "[117]\tvalid_0's multi_logloss: 2.03023\tvalid_0's auc_mu: 0.619305\n",
      "[118]\tvalid_0's multi_logloss: 2.03016\tvalid_0's auc_mu: 0.619333\n",
      "[119]\tvalid_0's multi_logloss: 2.03006\tvalid_0's auc_mu: 0.619365\n",
      "[120]\tvalid_0's multi_logloss: 2.02983\tvalid_0's auc_mu: 0.61946\n",
      "[121]\tvalid_0's multi_logloss: 2.02978\tvalid_0's auc_mu: 0.619461\n",
      "[122]\tvalid_0's multi_logloss: 2.02975\tvalid_0's auc_mu: 0.619419\n",
      "[123]\tvalid_0's multi_logloss: 2.02972\tvalid_0's auc_mu: 0.6194\n",
      "[124]\tvalid_0's multi_logloss: 2.02961\tvalid_0's auc_mu: 0.619461\n",
      "[125]\tvalid_0's multi_logloss: 2.02955\tvalid_0's auc_mu: 0.619474\n",
      "[126]\tvalid_0's multi_logloss: 2.02946\tvalid_0's auc_mu: 0.619496\n",
      "[127]\tvalid_0's multi_logloss: 2.02927\tvalid_0's auc_mu: 0.619609\n",
      "[128]\tvalid_0's multi_logloss: 2.02919\tvalid_0's auc_mu: 0.619623\n",
      "[129]\tvalid_0's multi_logloss: 2.02914\tvalid_0's auc_mu: 0.619648\n",
      "[130]\tvalid_0's multi_logloss: 2.02882\tvalid_0's auc_mu: 0.619808\n",
      "[131]\tvalid_0's multi_logloss: 2.02877\tvalid_0's auc_mu: 0.619832\n",
      "[132]\tvalid_0's multi_logloss: 2.02867\tvalid_0's auc_mu: 0.619902\n",
      "[133]\tvalid_0's multi_logloss: 2.02863\tvalid_0's auc_mu: 0.61991\n",
      "[134]\tvalid_0's multi_logloss: 2.02859\tvalid_0's auc_mu: 0.619938\n",
      "[135]\tvalid_0's multi_logloss: 2.02852\tvalid_0's auc_mu: 0.619963\n",
      "[136]\tvalid_0's multi_logloss: 2.02843\tvalid_0's auc_mu: 0.620004\n",
      "[137]\tvalid_0's multi_logloss: 2.02839\tvalid_0's auc_mu: 0.619995\n",
      "[138]\tvalid_0's multi_logloss: 2.02813\tvalid_0's auc_mu: 0.620053\n",
      "[139]\tvalid_0's multi_logloss: 2.02813\tvalid_0's auc_mu: 0.619986\n",
      "[140]\tvalid_0's multi_logloss: 2.02803\tvalid_0's auc_mu: 0.620048\n",
      "[141]\tvalid_0's multi_logloss: 2.028\tvalid_0's auc_mu: 0.620048\n",
      "[142]\tvalid_0's multi_logloss: 2.02794\tvalid_0's auc_mu: 0.620074\n",
      "[143]\tvalid_0's multi_logloss: 2.02773\tvalid_0's auc_mu: 0.620139\n",
      "[144]\tvalid_0's multi_logloss: 2.02768\tvalid_0's auc_mu: 0.620173\n",
      "[145]\tvalid_0's multi_logloss: 2.02761\tvalid_0's auc_mu: 0.620231\n",
      "[146]\tvalid_0's multi_logloss: 2.02755\tvalid_0's auc_mu: 0.620269\n",
      "[147]\tvalid_0's multi_logloss: 2.02745\tvalid_0's auc_mu: 0.620358\n",
      "[148]\tvalid_0's multi_logloss: 2.02723\tvalid_0's auc_mu: 0.620456\n",
      "[149]\tvalid_0's multi_logloss: 2.027\tvalid_0's auc_mu: 0.62058\n",
      "[150]\tvalid_0's multi_logloss: 2.0269\tvalid_0's auc_mu: 0.620666\n",
      "[151]\tvalid_0's multi_logloss: 2.0269\tvalid_0's auc_mu: 0.62063\n",
      "[152]\tvalid_0's multi_logloss: 2.02683\tvalid_0's auc_mu: 0.620653\n",
      "[153]\tvalid_0's multi_logloss: 2.02684\tvalid_0's auc_mu: 0.620606\n",
      "[154]\tvalid_0's multi_logloss: 2.02676\tvalid_0's auc_mu: 0.620628\n",
      "[155]\tvalid_0's multi_logloss: 2.02664\tvalid_0's auc_mu: 0.620681\n",
      "[156]\tvalid_0's multi_logloss: 2.02663\tvalid_0's auc_mu: 0.620647\n",
      "[157]\tvalid_0's multi_logloss: 2.02645\tvalid_0's auc_mu: 0.620694\n",
      "[158]\tvalid_0's multi_logloss: 2.02644\tvalid_0's auc_mu: 0.620651\n",
      "[159]\tvalid_0's multi_logloss: 2.02626\tvalid_0's auc_mu: 0.6207\n",
      "[160]\tvalid_0's multi_logloss: 2.02625\tvalid_0's auc_mu: 0.620661\n",
      "[161]\tvalid_0's multi_logloss: 2.0262\tvalid_0's auc_mu: 0.620651\n",
      "[162]\tvalid_0's multi_logloss: 2.02615\tvalid_0's auc_mu: 0.620671\n",
      "[163]\tvalid_0's multi_logloss: 2.02613\tvalid_0's auc_mu: 0.620655\n",
      "[164]\tvalid_0's multi_logloss: 2.02608\tvalid_0's auc_mu: 0.620736\n",
      "[165]\tvalid_0's multi_logloss: 2.02605\tvalid_0's auc_mu: 0.620748\n",
      "[166]\tvalid_0's multi_logloss: 2.026\tvalid_0's auc_mu: 0.620786\n",
      "[167]\tvalid_0's multi_logloss: 2.02597\tvalid_0's auc_mu: 0.620818\n",
      "[168]\tvalid_0's multi_logloss: 2.02582\tvalid_0's auc_mu: 0.620865\n",
      "[169]\tvalid_0's multi_logloss: 2.02579\tvalid_0's auc_mu: 0.620853\n",
      "[170]\tvalid_0's multi_logloss: 2.02575\tvalid_0's auc_mu: 0.620854\n",
      "[171]\tvalid_0's multi_logloss: 2.02547\tvalid_0's auc_mu: 0.620928\n",
      "[172]\tvalid_0's multi_logloss: 2.02546\tvalid_0's auc_mu: 0.620905\n",
      "[173]\tvalid_0's multi_logloss: 2.02543\tvalid_0's auc_mu: 0.620914\n",
      "[174]\tvalid_0's multi_logloss: 2.0254\tvalid_0's auc_mu: 0.620915\n",
      "[175]\tvalid_0's multi_logloss: 2.02536\tvalid_0's auc_mu: 0.620945\n",
      "[176]\tvalid_0's multi_logloss: 2.02536\tvalid_0's auc_mu: 0.620911\n",
      "[177]\tvalid_0's multi_logloss: 2.02529\tvalid_0's auc_mu: 0.620948\n",
      "[178]\tvalid_0's multi_logloss: 2.02527\tvalid_0's auc_mu: 0.62094\n",
      "[179]\tvalid_0's multi_logloss: 2.02522\tvalid_0's auc_mu: 0.620951\n",
      "[180]\tvalid_0's multi_logloss: 2.02523\tvalid_0's auc_mu: 0.620912\n",
      "[181]\tvalid_0's multi_logloss: 2.02509\tvalid_0's auc_mu: 0.620935\n",
      "[182]\tvalid_0's multi_logloss: 2.02509\tvalid_0's auc_mu: 0.620884\n",
      "[183]\tvalid_0's multi_logloss: 2.02505\tvalid_0's auc_mu: 0.620858\n",
      "[184]\tvalid_0's multi_logloss: 2.02503\tvalid_0's auc_mu: 0.620856\n",
      "[185]\tvalid_0's multi_logloss: 2.02491\tvalid_0's auc_mu: 0.62088\n",
      "[186]\tvalid_0's multi_logloss: 2.02462\tvalid_0's auc_mu: 0.620995\n",
      "[187]\tvalid_0's multi_logloss: 2.02459\tvalid_0's auc_mu: 0.620954\n",
      "[188]\tvalid_0's multi_logloss: 2.02455\tvalid_0's auc_mu: 0.620981\n",
      "[189]\tvalid_0's multi_logloss: 2.02452\tvalid_0's auc_mu: 0.62102\n",
      "[190]\tvalid_0's multi_logloss: 2.02446\tvalid_0's auc_mu: 0.621034\n",
      "[191]\tvalid_0's multi_logloss: 2.02443\tvalid_0's auc_mu: 0.621086\n",
      "[192]\tvalid_0's multi_logloss: 2.02442\tvalid_0's auc_mu: 0.621072\n",
      "[193]\tvalid_0's multi_logloss: 2.02431\tvalid_0's auc_mu: 0.621139\n",
      "[194]\tvalid_0's multi_logloss: 2.02428\tvalid_0's auc_mu: 0.621125\n",
      "[195]\tvalid_0's multi_logloss: 2.02416\tvalid_0's auc_mu: 0.621141\n",
      "[196]\tvalid_0's multi_logloss: 2.02413\tvalid_0's auc_mu: 0.621185\n",
      "[197]\tvalid_0's multi_logloss: 2.02413\tvalid_0's auc_mu: 0.621188\n",
      "[198]\tvalid_0's multi_logloss: 2.0241\tvalid_0's auc_mu: 0.621217\n",
      "[199]\tvalid_0's multi_logloss: 2.02409\tvalid_0's auc_mu: 0.621193\n",
      "[200]\tvalid_0's multi_logloss: 2.02403\tvalid_0's auc_mu: 0.621208\n",
      "[201]\tvalid_0's multi_logloss: 2.02401\tvalid_0's auc_mu: 0.621224\n",
      "[202]\tvalid_0's multi_logloss: 2.02399\tvalid_0's auc_mu: 0.621231\n",
      "[203]\tvalid_0's multi_logloss: 2.02395\tvalid_0's auc_mu: 0.621279\n",
      "[204]\tvalid_0's multi_logloss: 2.02395\tvalid_0's auc_mu: 0.621248\n",
      "[205]\tvalid_0's multi_logloss: 2.02396\tvalid_0's auc_mu: 0.621223\n",
      "[206]\tvalid_0's multi_logloss: 2.02392\tvalid_0's auc_mu: 0.621248\n",
      "[207]\tvalid_0's multi_logloss: 2.02391\tvalid_0's auc_mu: 0.621197\n",
      "[208]\tvalid_0's multi_logloss: 2.0238\tvalid_0's auc_mu: 0.62119\n",
      "[209]\tvalid_0's multi_logloss: 2.02378\tvalid_0's auc_mu: 0.621207\n",
      "[210]\tvalid_0's multi_logloss: 2.0238\tvalid_0's auc_mu: 0.621167\n",
      "[211]\tvalid_0's multi_logloss: 2.02376\tvalid_0's auc_mu: 0.621205\n",
      "[212]\tvalid_0's multi_logloss: 2.02371\tvalid_0's auc_mu: 0.621224\n",
      "[213]\tvalid_0's multi_logloss: 2.0237\tvalid_0's auc_mu: 0.621256\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 2.02395\tvalid_0's auc_mu: 0.621279\n"
     ]
    }
   ],
   "source": [
    "#获取预测的缺失值\r\n",
    "train = set_missing(train, estimate_list, miss_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's multi_logloss: 2.10912\tvalid_0's auc_mu: 0.582548\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.10081\tvalid_0's auc_mu: 0.58661\n",
      "[3]\tvalid_0's multi_logloss: 2.09433\tvalid_0's auc_mu: 0.58809\n",
      "[4]\tvalid_0's multi_logloss: 2.08885\tvalid_0's auc_mu: 0.591025\n",
      "[5]\tvalid_0's multi_logloss: 2.0844\tvalid_0's auc_mu: 0.592465\n",
      "[6]\tvalid_0's multi_logloss: 2.08081\tvalid_0's auc_mu: 0.593494\n",
      "[7]\tvalid_0's multi_logloss: 2.07771\tvalid_0's auc_mu: 0.594067\n",
      "[8]\tvalid_0's multi_logloss: 2.0751\tvalid_0's auc_mu: 0.594438\n",
      "[9]\tvalid_0's multi_logloss: 2.07291\tvalid_0's auc_mu: 0.594954\n",
      "[10]\tvalid_0's multi_logloss: 2.07095\tvalid_0's auc_mu: 0.5957\n",
      "[11]\tvalid_0's multi_logloss: 2.069\tvalid_0's auc_mu: 0.596424\n",
      "[12]\tvalid_0's multi_logloss: 2.06744\tvalid_0's auc_mu: 0.597314\n",
      "[13]\tvalid_0's multi_logloss: 2.06613\tvalid_0's auc_mu: 0.597584\n",
      "[14]\tvalid_0's multi_logloss: 2.06472\tvalid_0's auc_mu: 0.597939\n",
      "[15]\tvalid_0's multi_logloss: 2.06353\tvalid_0's auc_mu: 0.598243\n",
      "[16]\tvalid_0's multi_logloss: 2.0627\tvalid_0's auc_mu: 0.598288\n",
      "[17]\tvalid_0's multi_logloss: 2.06168\tvalid_0's auc_mu: 0.59854\n",
      "[18]\tvalid_0's multi_logloss: 2.06066\tvalid_0's auc_mu: 0.599346\n",
      "[19]\tvalid_0's multi_logloss: 2.05985\tvalid_0's auc_mu: 0.600174\n",
      "[20]\tvalid_0's multi_logloss: 2.05899\tvalid_0's auc_mu: 0.600527\n",
      "[21]\tvalid_0's multi_logloss: 2.05839\tvalid_0's auc_mu: 0.600726\n",
      "[22]\tvalid_0's multi_logloss: 2.05738\tvalid_0's auc_mu: 0.601636\n",
      "[23]\tvalid_0's multi_logloss: 2.05652\tvalid_0's auc_mu: 0.602363\n",
      "[24]\tvalid_0's multi_logloss: 2.05588\tvalid_0's auc_mu: 0.602771\n",
      "[25]\tvalid_0's multi_logloss: 2.05544\tvalid_0's auc_mu: 0.602691\n",
      "[26]\tvalid_0's multi_logloss: 2.05485\tvalid_0's auc_mu: 0.603153\n",
      "[27]\tvalid_0's multi_logloss: 2.05437\tvalid_0's auc_mu: 0.60335\n",
      "[28]\tvalid_0's multi_logloss: 2.05378\tvalid_0's auc_mu: 0.603727\n",
      "[29]\tvalid_0's multi_logloss: 2.05338\tvalid_0's auc_mu: 0.603835\n",
      "[30]\tvalid_0's multi_logloss: 2.05282\tvalid_0's auc_mu: 0.604115\n",
      "[31]\tvalid_0's multi_logloss: 2.05238\tvalid_0's auc_mu: 0.604434\n",
      "[32]\tvalid_0's multi_logloss: 2.05198\tvalid_0's auc_mu: 0.604666\n",
      "[33]\tvalid_0's multi_logloss: 2.05122\tvalid_0's auc_mu: 0.605358\n",
      "[34]\tvalid_0's multi_logloss: 2.05079\tvalid_0's auc_mu: 0.605761\n",
      "[35]\tvalid_0's multi_logloss: 2.05051\tvalid_0's auc_mu: 0.605917\n",
      "[36]\tvalid_0's multi_logloss: 2.05008\tvalid_0's auc_mu: 0.606247\n",
      "[37]\tvalid_0's multi_logloss: 2.0497\tvalid_0's auc_mu: 0.60617\n",
      "[38]\tvalid_0's multi_logloss: 2.049\tvalid_0's auc_mu: 0.606428\n",
      "[39]\tvalid_0's multi_logloss: 2.04873\tvalid_0's auc_mu: 0.606395\n",
      "[40]\tvalid_0's multi_logloss: 2.04846\tvalid_0's auc_mu: 0.606541\n",
      "[41]\tvalid_0's multi_logloss: 2.04831\tvalid_0's auc_mu: 0.606366\n",
      "[42]\tvalid_0's multi_logloss: 2.04808\tvalid_0's auc_mu: 0.606628\n",
      "[43]\tvalid_0's multi_logloss: 2.04786\tvalid_0's auc_mu: 0.606589\n",
      "[44]\tvalid_0's multi_logloss: 2.04759\tvalid_0's auc_mu: 0.606715\n",
      "[45]\tvalid_0's multi_logloss: 2.04742\tvalid_0's auc_mu: 0.606744\n",
      "[46]\tvalid_0's multi_logloss: 2.04717\tvalid_0's auc_mu: 0.60685\n",
      "[47]\tvalid_0's multi_logloss: 2.04683\tvalid_0's auc_mu: 0.607024\n",
      "[48]\tvalid_0's multi_logloss: 2.04655\tvalid_0's auc_mu: 0.60716\n",
      "[49]\tvalid_0's multi_logloss: 2.04634\tvalid_0's auc_mu: 0.607274\n",
      "[50]\tvalid_0's multi_logloss: 2.04625\tvalid_0's auc_mu: 0.607106\n",
      "[51]\tvalid_0's multi_logloss: 2.04597\tvalid_0's auc_mu: 0.607257\n",
      "[52]\tvalid_0's multi_logloss: 2.0459\tvalid_0's auc_mu: 0.607228\n",
      "[53]\tvalid_0's multi_logloss: 2.04564\tvalid_0's auc_mu: 0.607507\n",
      "[54]\tvalid_0's multi_logloss: 2.04548\tvalid_0's auc_mu: 0.60758\n",
      "[55]\tvalid_0's multi_logloss: 2.04532\tvalid_0's auc_mu: 0.607605\n",
      "[56]\tvalid_0's multi_logloss: 2.04518\tvalid_0's auc_mu: 0.607631\n",
      "[57]\tvalid_0's multi_logloss: 2.04496\tvalid_0's auc_mu: 0.607591\n",
      "[58]\tvalid_0's multi_logloss: 2.04479\tvalid_0's auc_mu: 0.607652\n",
      "[59]\tvalid_0's multi_logloss: 2.04469\tvalid_0's auc_mu: 0.607689\n",
      "[60]\tvalid_0's multi_logloss: 2.04458\tvalid_0's auc_mu: 0.607708\n",
      "[61]\tvalid_0's multi_logloss: 2.04446\tvalid_0's auc_mu: 0.607811\n",
      "[62]\tvalid_0's multi_logloss: 2.04421\tvalid_0's auc_mu: 0.607725\n",
      "[63]\tvalid_0's multi_logloss: 2.04403\tvalid_0's auc_mu: 0.607889\n",
      "[64]\tvalid_0's multi_logloss: 2.04397\tvalid_0's auc_mu: 0.607796\n",
      "[65]\tvalid_0's multi_logloss: 2.04391\tvalid_0's auc_mu: 0.607679\n",
      "[66]\tvalid_0's multi_logloss: 2.04384\tvalid_0's auc_mu: 0.607758\n",
      "[67]\tvalid_0's multi_logloss: 2.04367\tvalid_0's auc_mu: 0.6078\n",
      "[68]\tvalid_0's multi_logloss: 2.04347\tvalid_0's auc_mu: 0.607822\n",
      "[69]\tvalid_0's multi_logloss: 2.04336\tvalid_0's auc_mu: 0.607798\n",
      "[70]\tvalid_0's multi_logloss: 2.04314\tvalid_0's auc_mu: 0.608015\n",
      "[71]\tvalid_0's multi_logloss: 2.04309\tvalid_0's auc_mu: 0.607996\n",
      "[72]\tvalid_0's multi_logloss: 2.04278\tvalid_0's auc_mu: 0.608226\n",
      "[73]\tvalid_0's multi_logloss: 2.04265\tvalid_0's auc_mu: 0.608424\n",
      "[74]\tvalid_0's multi_logloss: 2.04258\tvalid_0's auc_mu: 0.60836\n",
      "[75]\tvalid_0's multi_logloss: 2.04255\tvalid_0's auc_mu: 0.608377\n",
      "[76]\tvalid_0's multi_logloss: 2.04246\tvalid_0's auc_mu: 0.60849\n",
      "[77]\tvalid_0's multi_logloss: 2.04234\tvalid_0's auc_mu: 0.608485\n",
      "[78]\tvalid_0's multi_logloss: 2.04225\tvalid_0's auc_mu: 0.608386\n",
      "[79]\tvalid_0's multi_logloss: 2.04209\tvalid_0's auc_mu: 0.608312\n",
      "[80]\tvalid_0's multi_logloss: 2.04204\tvalid_0's auc_mu: 0.608417\n",
      "[81]\tvalid_0's multi_logloss: 2.04202\tvalid_0's auc_mu: 0.608407\n",
      "[82]\tvalid_0's multi_logloss: 2.04192\tvalid_0's auc_mu: 0.608615\n",
      "[83]\tvalid_0's multi_logloss: 2.04179\tvalid_0's auc_mu: 0.608762\n",
      "[84]\tvalid_0's multi_logloss: 2.04149\tvalid_0's auc_mu: 0.608902\n",
      "[85]\tvalid_0's multi_logloss: 2.0414\tvalid_0's auc_mu: 0.609138\n",
      "[86]\tvalid_0's multi_logloss: 2.04138\tvalid_0's auc_mu: 0.609256\n",
      "[87]\tvalid_0's multi_logloss: 2.04138\tvalid_0's auc_mu: 0.609121\n",
      "[88]\tvalid_0's multi_logloss: 2.04129\tvalid_0's auc_mu: 0.609142\n",
      "[89]\tvalid_0's multi_logloss: 2.04125\tvalid_0's auc_mu: 0.609064\n",
      "[90]\tvalid_0's multi_logloss: 2.04106\tvalid_0's auc_mu: 0.60926\n",
      "[91]\tvalid_0's multi_logloss: 2.04093\tvalid_0's auc_mu: 0.609375\n",
      "[92]\tvalid_0's multi_logloss: 2.04077\tvalid_0's auc_mu: 0.60936\n",
      "[93]\tvalid_0's multi_logloss: 2.04073\tvalid_0's auc_mu: 0.609341\n",
      "[94]\tvalid_0's multi_logloss: 2.04064\tvalid_0's auc_mu: 0.60936\n",
      "[95]\tvalid_0's multi_logloss: 2.04064\tvalid_0's auc_mu: 0.609277\n",
      "[96]\tvalid_0's multi_logloss: 2.04061\tvalid_0's auc_mu: 0.609227\n",
      "[97]\tvalid_0's multi_logloss: 2.04061\tvalid_0's auc_mu: 0.609306\n",
      "[98]\tvalid_0's multi_logloss: 2.04047\tvalid_0's auc_mu: 0.60938\n",
      "[99]\tvalid_0's multi_logloss: 2.04041\tvalid_0's auc_mu: 0.609438\n",
      "[100]\tvalid_0's multi_logloss: 2.04026\tvalid_0's auc_mu: 0.609452\n",
      "[101]\tvalid_0's multi_logloss: 2.04025\tvalid_0's auc_mu: 0.609353\n",
      "[102]\tvalid_0's multi_logloss: 2.04022\tvalid_0's auc_mu: 0.609372\n",
      "[103]\tvalid_0's multi_logloss: 2.04011\tvalid_0's auc_mu: 0.609346\n",
      "[104]\tvalid_0's multi_logloss: 2.0401\tvalid_0's auc_mu: 0.609321\n",
      "[105]\tvalid_0's multi_logloss: 2.04008\tvalid_0's auc_mu: 0.60929\n",
      "[106]\tvalid_0's multi_logloss: 2.03967\tvalid_0's auc_mu: 0.609414\n",
      "[107]\tvalid_0's multi_logloss: 2.03969\tvalid_0's auc_mu: 0.609271\n",
      "[108]\tvalid_0's multi_logloss: 2.03968\tvalid_0's auc_mu: 0.609214\n",
      "[109]\tvalid_0's multi_logloss: 2.03953\tvalid_0's auc_mu: 0.609319\n",
      "[110]\tvalid_0's multi_logloss: 2.03959\tvalid_0's auc_mu: 0.609171\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 2.04026\tvalid_0's auc_mu: 0.609452\n"
     ]
    }
   ],
   "source": [
    "estimate_list = list(testA.columns)\r\n",
    "estimate_list.remove('employmentLength')\r\n",
    "miss_col = 'employmentLength'\r\n",
    "testA = set_missing(testA, estimate_list, miss_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_fea = list(categorical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#方法1 使用众数补充空值，众数可能返回多个\r\n",
    "train[categorical_fea] = train[categorical_fea].fillna(train[categorical_fea].mode()[0])\r\n",
    "testA[categorical_fea] = testA[categorical_fea].fillna(testA[categorical_fea].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 标签编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1',\n",
       "       'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2',\n",
       "       'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2', 'G3',\n",
       "       'G4', 'G5'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#标签编码 grade、subGrade\r\n",
    "\r\n",
    "# merge_data['grade'].unique(), \r\n",
    "np.sort(merge_data['subGrade'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grade_map = dict(zip(('A', 'B', 'C', 'D', 'E', 'F', 'G'), (0, 5, 10, 15, 20, 25, 30, 35)))\r\n",
    "subGrade_map =dict(zip(('A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2','E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2', 'G3', 'G4', 'G5'),\r\n",
    "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['grade'] = train['grade'].map(grade_map)\r\n",
    "testA['grade'] = testA['grade'].map(grade_map)\r\n",
    "\r\n",
    "train['subGrade'] = train['subGrade'].map(subGrade_map)\r\n",
    "testA['subGrade'] = testA['subGrade'].map(subGrade_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2 years', '5 years', '8 years', '10+ years', nan, '7 years',\n",
       "       '9 years', '1 year', '3 years', '< 1 year', '4 years', '6 years'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签编码 employmentLength\r\n",
    "\r\n",
    "merge_data['employmentLength'].unique()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "employmentLength_map = dict(zip(( '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years'),\r\n",
    "(0 , 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['employmentLength'] = train['employmentLength'].map(employmentLength_map)\r\n",
    "testA['employmentLength'] = testA['employmentLength'].map(employmentLength_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2007-06-01'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#标签编码 issueDate\t\r\n",
    "\r\n",
    "merge_data['issueDate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['issueDate'] = pd.to_datetime(train['issueDate'])\r\n",
    "testA['issueDate'] = pd.to_datetime(testA['issueDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['issueDate_year'] = pd.to_datetime(train['issueDate']).dt.year\r\n",
    "train['issueDate_month'] = pd.to_datetime(train['issueDate']).dt.month\r\n",
    "\r\n",
    "testA['issueDate_year'] = pd.to_datetime(testA['issueDate']).dt.year\r\n",
    "testA['issueDate_month'] = pd.to_datetime(testA['issueDate']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "base_time = pd.datetime.strptime('2007-06-01', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['issueDate_diff'] = train['issueDate'].apply(lambda x: (x - base_time).days)\r\n",
    "testA['issueDate_diff'] = testA['issueDate'].apply(lambda x: (x - base_time).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(columns='issueDate', inplace = True)\r\n",
    "testA.drop(columns='issueDate', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1944-01-01 00:00:00')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签编码 earliesCreditLine\r\n",
    "pd.to_datetime(merge_data['earliesCreditLine']).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "base_time2 = pd.datetime.strptime('1944-01-01', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['earliesCreditLine'] = pd.to_datetime(train['earliesCreditLine'])\r\n",
    "testA['earliesCreditLine'] = pd.to_datetime(testA['earliesCreditLine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['earliesCreditLine_year'] = pd.to_datetime(train['earliesCreditLine']).dt.year\r\n",
    "train['earliesCreditLine_month'] = pd.to_datetime(train['earliesCreditLine']).dt.month\r\n",
    "\r\n",
    "testA['earliesCreditLine_year'] = pd.to_datetime(testA['earliesCreditLine']).dt.year\r\n",
    "testA['earliesCreditLine_month'] = pd.to_datetime(testA['earliesCreditLine']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['earliesCreditLine_diff'] = train['earliesCreditLine'].apply(lambda x: (x - base_time2).days)\r\n",
    "testA['earliesCreditLine_diff'] = testA['earliesCreditLine'].apply(lambda x: (x - base_time2).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(columns='earliesCreditLine', inplace = True)\r\n",
    "testA.drop(columns='earliesCreditLine', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 保存初步特征工程后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['isDefault'])\r\n",
    "y_train = train[['isDefault']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_testA = testA.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/X_train.csv', 'wb') as file:\r\n",
    "    pickle.dump(X_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/y_train.csv', 'wb') as file:\r\n",
    "    pickle.dump(y_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/X_testA.csv', 'wb') as file:\r\n",
    "    pickle.dump(X_testA, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 提取、切割数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/X_train.csv', 'rb') as file:\r\n",
    "    X_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/y_train.csv', 'rb') as file:\r\n",
    "    y_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/features/X_testA.csv', 'rb') as file:\r\n",
    "    X_testA = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_eval,y_train,y_eval=train_test_split(X_train,y_train,test_size=0.2,random_state=1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用lgbm训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAYAAADuMJi0AAAGR0lEQVR42rVZ21IbRxBtCbQrkIR2dQVjsLmDLBsET3nTQ8ouYRkQVf6e/E9+Im958qMfkgoXAaKSSj6C9Jnd2R2NeiRSRaZqitVOT5+Z6dNnWoKGlN94JFp8Ipofkb/7SOXjGyp8wF+z35K3f0uUp/GW4XfLQ8v2gefj3ZCCzojoNfue+43o1Q3l3xB/yA3JO7jnF2pCLnI+pNyx/qw7L+SQ7T2N9p2f8c60QcfcK6KGXsAd+ZvA4LlZYuSSAoOhMs5vwJkEGDlbPMaJoA+FcQ0IH38QLWkbAFLkOOhoMF5tU6/eBRhNjro0ZgKiPRAt3FLhCO/vqdgmNTm32LkmKpvBmQY4q5uAaAgbwDBG2BVv3bfI8KKAMWj2kfw9+pkZREIbEql4ST1x7hgHIANkbJ//MF8mAH/ilTCJ2tIi4ASr1IC3VNqXHKOxjy34mgoImnOQtx1g81fkqTiMOBVGcTogNhiT5iBHET8R8C+iApJUmgim3SQAXhsLQz7ee2G8gOAQNtJckBEplADiAxtX+G9NmhDl0qJKnTvyWlAMPYZnvIviGXRg6/Dh824DBXhP/tbfREXJEIvQ+aaPGjG7pvw6r3xdx+9hqb4dgZaP2XmdHO2K/B0c1+oUph6k8kShBryl/Ft0DYgjTlOieOACHFFpVyUl72T9V3cM1jUoYvxIC2vpCSys/ck70mDYuYvdvKjlMdKAUThneWVU1aAsyjv6PURDiwNsHGBZzY+JtAAgE2TFxdRHJdyIp/f+zqu09M5cDP2F08Ukkpj4YNSdX950HY2pNCCUK/Hhx5ZMBfjNSEzdsIihVzzAMdn9dz4eDYhnyQb9SSCiAryiJcQk82LiTbJ4x2FZJaUenpKnzP95WyDf4Y+QN9EFHHSeDLGdBjjKNQ5vKHf4XMA7KrY0y0GEObBOO/8e1ywuQExOHXktuQyJALEBpcEqhwtHqgiDuCK5b6i0p2MQpcckIIoh+6hYgTZtO8xlMi6O4tKCF/kOGHEg/W0UUpHW0ZoGNZ1ExZWcn7EErgwt4uj50E/sFBjXXIayWvh7WryjasxarZKssXon0zxvvkc32Q0bqbBCuZiKt9dWFysfQefeL29JYFaeztX6tePaZdz5mYx8+6Zq3Mk0wXECQxlhdzgS2wjBHju3j1RIgKyOMdNUE8X0+RAdbSapS11MRCv1SzUXmO6wGZe2SQYrv2MvCSWEv2VODE6DN7bz8ufypgQKW7uQskFTQHULLKyaEyrnlZbgOGLrV5qrn9U79jjm2HJmgkaVN98AfBub91lGPLZBqdroN5LYgjSu4zYZDDHXZOIPC691HqrWI1900I8qLzgKP4ft8DxEWigprPfrO+KcXno9gZz4jjGewWdUcpGCj0qVFuGPYbl2VturndZ2qRvlL8acDO6lF/DY/VjsFesiUK+ypJ+r/ep+cJkSQxEK4PG4WozgA75TYrDDqStE69K8/mzGEM+JXTeqvmedEElMmwCMm2SLd6bNNF9su02zEtoW6nAQtpMj5Gd7fKa//wqonF7UdtHFsVn+6hf1o7AfriPH7M6EeIUEF5zKVxXbYo7kS/OEtOqDYZKPoBsETIixn0uYrasThmzDkhdKPkz2EnaX0HdQbIgr59vAdGYDqjHrxkjS7WOxkTD8sqEqhiwcJETgBYigrBqF08KyDaje9SZ/I1A7MzaTzMGDEulPtZUkuKcyIRAjxEJPVrnVlb/9wkfij31D/pQt1IN+iL8bGJcstBIO7Y5VI/cwDqURbXhMuJxBqD0KLoK3esWFs0Jz5i5ZvJUAfFJMFb9XmGIOnzGpijpcWYCaMqXSQWp8EnCABepQ0Elyi4wfKfsw78ikIqif1pe1AGPlLmojl1SKxHHXp1L+Ut7AmDQHvhI5xHGi4EooO2BR7k78PEkJOdL7cAxQUZ/Tyclu9gnfwGgOmm2lNHGNmZXsq4Pqgc1EG1ATrvKl8s4R9ywwnqulGUnaRLVhxy8v3ieUwy2hbooT68uscW++DCDH0WSzuoyN2D4LUJ/tLECbcSKznwMIFs0ChF4mRTCnQbIIfk4SHJo6A9BMuTnXTs3Ku/KxsgZWqzuSe+Os8cEUfnMBY6UF5gi3SUbd5K7vDjq5WW0UENJlRsWn4sy21Er/E/AvPQSFHy1p4fgAAAAASUVORK5CYII=');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### lgbm 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_ex = lgb.LGBMClassifier(objective='binary', metric = 'binary_logloss,auc', n_estimators=200, \r\n",
    "                            scale_pos_weight=4, #sample_pos_weight = number of negative samples / number of positive samples\r\n",
    "                            max_depth=7, learning_rate=0.1,\r\n",
    "                            bagging_fraction = 1,feature_fraction = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 1 调整max_depth 和 num_leaves\n",
    "\n",
    "这两个参数基本可以确定树的大小及复杂度，可以同时调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\r\n",
    "    'max_depth': [4,6,8],\r\n",
    "    'num_leaves': [20,30,40,50]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "参数的最佳取值:{'max_depth': 6, 'num_leaves': 50}\n",
      "最佳模型得分:0.7344691189631142\n",
      "[0.73441213 0.73446912 0.73442406]\n",
      "[{'max_depth': 6, 'num_leaves': 45}, {'max_depth': 6, 'num_leaves': 50}, {'max_depth': 6, 'num_leaves': 60}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step2 调整min_data_in_leaf 和 min_sum_hessian_in_leaf\n",
    "\n",
    "该步骤主要是防止树过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\r\n",
    "'min_child_samples': [18,19,20,21,22],\r\n",
    "'min_child_weight': [0.001,0.002]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "参数的最佳取值:{'min_child_samples': 19, 'min_child_weight': 0.001}\n",
      "最佳模型得分:0.7341964588709182\n",
      "[0.73404514 0.73404514 0.73419646 0.73419646 0.73415597 0.73415597\n",
      " 0.73419078 0.73419078 0.73408484 0.73408484]\n",
      "[{'min_child_samples': 18, 'min_child_weight': 0.001}, {'min_child_samples': 18, 'min_child_weight': 0.002}, {'min_child_samples': 19, 'min_child_weight': 0.001}, {'min_child_samples': 19, 'min_child_weight': 0.002}, {'min_child_samples': 20, 'min_child_weight': 0.001}, {'min_child_samples': 20, 'min_child_weight': 0.002}, {'min_child_samples': 21, 'min_child_weight': 0.001}, {'min_child_samples': 21, 'min_child_weight': 0.002}, {'min_child_samples': 22, 'min_child_weight': 0.001}, {'min_child_samples': 22, 'min_child_weight': 0.002}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 3 调整feature_fraction\n",
    "\n",
    "该步骤主要是通过随机选择一定比列的特征去模型中，防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\r\n",
    "    'feature_fraction': [0.6, 0.8, 1]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "参数的最佳取值:{'feature_fraction': 0.8}\n",
      "最佳模型得分:0.734185926417038\n",
      "[0.73410324 0.73418593 0.73415597]\n",
      "[{'feature_fraction': 0.6}, {'feature_fraction': 0.8}, {'feature_fraction': 1}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 4 调整bagging_fraction和bagging_freq\n",
    "bagging_fraction+bagging_freq参数必须同时设置，bagging_fraction相当于subsample样本采样，可以使bagging更快的运行，同时也可以降拟合。bagging_freq默认0，表示bagging的频率，0意味着没有使用bagging，k意味着每k轮迭代进行一次bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\r\n",
    "     'bagging_fraction': [0.8,0.9,1],\r\n",
    "     'bagging_freq': [2,3,4]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "参数的最佳取值:{'bagging_fraction': 0.9, 'bagging_freq': 2}\n",
      "最佳模型得分:0.7343761622674878\n",
      "[0.73436317 0.73422365 0.73408684 0.73437616 0.73410475 0.73422763\n",
      " 0.73415597 0.73415597 0.73415597]\n",
      "[{'bagging_fraction': 0.8, 'bagging_freq': 2}, {'bagging_fraction': 0.8, 'bagging_freq': 3}, {'bagging_fraction': 0.8, 'bagging_freq': 4}, {'bagging_fraction': 0.9, 'bagging_freq': 2}, {'bagging_fraction': 0.9, 'bagging_freq': 3}, {'bagging_fraction': 0.9, 'bagging_freq': 4}, {'bagging_fraction': 1, 'bagging_freq': 2}, {'bagging_fraction': 1, 'bagging_freq': 3}, {'bagging_fraction': 1, 'bagging_freq': 4}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 5 调整lambda_l1(reg_alpha)和lambda_l2(reg_lambda)\n",
    "本步骤通过L1正则化和L2正则化降低过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters = {\r\n",
    "#      'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100, 1000],\r\n",
    "#      'reg_lambda': [1e-5, 1e-2, 0.1, 1, 80, 100, 1000]\r\n",
    "# }\r\n",
    "\r\n",
    "parameters = {\r\n",
    "     'reg_alpha': [0.01],\r\n",
    "     'reg_lambda': [1e-2, 0.1, 1, 75]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "参数的最佳取值:{'reg_alpha': 0.01, 'reg_lambda': 75}\n",
      "最佳模型得分:0.7278459731596485\n",
      "[0.72590806 0.72591906 0.72586441 0.72784597]\n",
      "[{'reg_alpha': 0.01, 'reg_lambda': 0.01}, {'reg_alpha': 0.01, 'reg_lambda': 0.1}, {'reg_alpha': 0.01, 'reg_lambda': 1}, {'reg_alpha': 0.01, 'reg_lambda': 75}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 6 调整cat_smooth\n",
    "cat_smooth为设置每个类别拥有最小的个数，主要用于去噪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\r\n",
    "     'cat_smooth': [0,10,20]\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "参数的最佳取值:{'cat_smooth': 0}\n",
      "最佳模型得分:0.7341559665239824\n",
      "[0.73415597 0.73415597 0.73415597]\n",
      "[{'cat_smooth': 0}, {'cat_smooth': 10}, {'cat_smooth': 20}]\n"
     ]
    }
   ],
   "source": [
    "gsearch = GridSearchCV(clf_ex, param_grid=parameters, scoring='roc_auc', cv=5)\r\n",
    "gsearch.fit(X_train, y_train)\r\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\r\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\r\n",
    "print(gsearch.cv_results_['mean_test_score'])\r\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Step 7 最后，本人会适当调小learning_rate的值以及调整num_iterations的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 参数的最佳取值:{'max_depth': 6, 'num_leaves': 50}\r\n",
    "# 参数的最佳取值:{'min_child_samples': 19, 'min_child_weight': 0.001}\r\n",
    "# 参数的最佳取值:{'feature_fraction': 0.8}\r\n",
    "# 参数的最佳取值:{'bagging_fraction': 0.9, 'bagging_freq': 2}\r\n",
    "# 参数的最佳取值:{'reg_alpha': 0.01, 'reg_lambda': 75}\r\n",
    "\r\n",
    "# objective='binary', metric = 'binary_logloss,auc', \r\n",
    "#                             max_depth=6, num_leaves=50,\r\n",
    "#                             min_child_samples=19, min_child_weight=0.001,\r\n",
    "#                             feature_fraction=0.8,\r\n",
    "#                             bagging_fraction=0.9, bagging_freq=2,\r\n",
    "#                             reg_alpha=0.01, reg_lambda=75,\r\n",
    "#                             cat_smooth=0,\r\n",
    "#                             scale_pos_weight=4,\r\n",
    "#                             n_estimators=1000, learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_ex = lgb.LGBMClassifier(objective='binary', metric = 'binary_logloss,auc', \r\n",
    "                            max_depth=6, num_leaves=50,\r\n",
    "                            min_child_samples=19, min_child_weight=0.001,\r\n",
    "                            feature_fraction=0.8,\r\n",
    "                            bagging_fraction=0.9, bagging_freq=2,\r\n",
    "                            reg_alpha=0.01, reg_lambda=75,\r\n",
    "                            cat_smooth=0,\r\n",
    "                            scale_pos_weight=4,\r\n",
    "                            n_estimators=1000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['applicationType', 'employmentTitle', 'homeOwnership', 'initialListStatus', 'n11', 'n12', 'policyCode', 'postCode', 'purpose', 'regionCode', 'verificationStatus']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.499601\tvalid_0's auc: 0.700777\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.49948\tvalid_0's auc: 0.702616\n",
      "[3]\tvalid_0's binary_logloss: 0.499355\tvalid_0's auc: 0.706347\n",
      "[4]\tvalid_0's binary_logloss: 0.499236\tvalid_0's auc: 0.70684\n",
      "[5]\tvalid_0's binary_logloss: 0.499115\tvalid_0's auc: 0.707125\n",
      "[6]\tvalid_0's binary_logloss: 0.498995\tvalid_0's auc: 0.70727\n",
      "[7]\tvalid_0's binary_logloss: 0.498876\tvalid_0's auc: 0.706892\n",
      "[8]\tvalid_0's binary_logloss: 0.498759\tvalid_0's auc: 0.707296\n",
      "[9]\tvalid_0's binary_logloss: 0.498641\tvalid_0's auc: 0.707859\n",
      "[10]\tvalid_0's binary_logloss: 0.498523\tvalid_0's auc: 0.70801\n",
      "[11]\tvalid_0's binary_logloss: 0.498406\tvalid_0's auc: 0.707977\n",
      "[12]\tvalid_0's binary_logloss: 0.498292\tvalid_0's auc: 0.70777\n",
      "[13]\tvalid_0's binary_logloss: 0.498179\tvalid_0's auc: 0.707906\n",
      "[14]\tvalid_0's binary_logloss: 0.498066\tvalid_0's auc: 0.707887\n",
      "[15]\tvalid_0's binary_logloss: 0.497954\tvalid_0's auc: 0.707779\n",
      "[16]\tvalid_0's binary_logloss: 0.497845\tvalid_0's auc: 0.707989\n",
      "[17]\tvalid_0's binary_logloss: 0.497734\tvalid_0's auc: 0.708034\n",
      "[18]\tvalid_0's binary_logloss: 0.497622\tvalid_0's auc: 0.708071\n",
      "[19]\tvalid_0's binary_logloss: 0.497513\tvalid_0's auc: 0.708009\n",
      "[20]\tvalid_0's binary_logloss: 0.497403\tvalid_0's auc: 0.708046\n",
      "[21]\tvalid_0's binary_logloss: 0.497295\tvalid_0's auc: 0.708003\n",
      "[22]\tvalid_0's binary_logloss: 0.497191\tvalid_0's auc: 0.708209\n",
      "[23]\tvalid_0's binary_logloss: 0.497087\tvalid_0's auc: 0.708112\n",
      "[24]\tvalid_0's binary_logloss: 0.496982\tvalid_0's auc: 0.708055\n",
      "[25]\tvalid_0's binary_logloss: 0.496878\tvalid_0's auc: 0.708162\n",
      "[26]\tvalid_0's binary_logloss: 0.496776\tvalid_0's auc: 0.70837\n",
      "[27]\tvalid_0's binary_logloss: 0.496674\tvalid_0's auc: 0.708553\n",
      "[28]\tvalid_0's binary_logloss: 0.496572\tvalid_0's auc: 0.708467\n",
      "[29]\tvalid_0's binary_logloss: 0.496471\tvalid_0's auc: 0.708384\n",
      "[30]\tvalid_0's binary_logloss: 0.496372\tvalid_0's auc: 0.708467\n",
      "[31]\tvalid_0's binary_logloss: 0.496275\tvalid_0's auc: 0.708566\n",
      "[32]\tvalid_0's binary_logloss: 0.496176\tvalid_0's auc: 0.708691\n",
      "[33]\tvalid_0's binary_logloss: 0.496079\tvalid_0's auc: 0.708732\n",
      "[34]\tvalid_0's binary_logloss: 0.495985\tvalid_0's auc: 0.708806\n",
      "[35]\tvalid_0's binary_logloss: 0.495891\tvalid_0's auc: 0.708846\n",
      "[36]\tvalid_0's binary_logloss: 0.495796\tvalid_0's auc: 0.708987\n",
      "[37]\tvalid_0's binary_logloss: 0.495704\tvalid_0's auc: 0.708934\n",
      "[38]\tvalid_0's binary_logloss: 0.495609\tvalid_0's auc: 0.709025\n",
      "[39]\tvalid_0's binary_logloss: 0.495515\tvalid_0's auc: 0.709057\n",
      "[40]\tvalid_0's binary_logloss: 0.495423\tvalid_0's auc: 0.709031\n",
      "[41]\tvalid_0's binary_logloss: 0.495336\tvalid_0's auc: 0.709051\n",
      "[42]\tvalid_0's binary_logloss: 0.495247\tvalid_0's auc: 0.709122\n",
      "[43]\tvalid_0's binary_logloss: 0.495156\tvalid_0's auc: 0.70913\n",
      "[44]\tvalid_0's binary_logloss: 0.495069\tvalid_0's auc: 0.709233\n",
      "[45]\tvalid_0's binary_logloss: 0.494982\tvalid_0's auc: 0.709205\n",
      "[46]\tvalid_0's binary_logloss: 0.494894\tvalid_0's auc: 0.709192\n",
      "[47]\tvalid_0's binary_logloss: 0.494809\tvalid_0's auc: 0.709145\n",
      "[48]\tvalid_0's binary_logloss: 0.494722\tvalid_0's auc: 0.70911\n",
      "[49]\tvalid_0's binary_logloss: 0.494638\tvalid_0's auc: 0.709088\n",
      "[50]\tvalid_0's binary_logloss: 0.494554\tvalid_0's auc: 0.709051\n",
      "[51]\tvalid_0's binary_logloss: 0.49447\tvalid_0's auc: 0.709036\n",
      "[52]\tvalid_0's binary_logloss: 0.494388\tvalid_0's auc: 0.709014\n",
      "[53]\tvalid_0's binary_logloss: 0.494306\tvalid_0's auc: 0.709075\n",
      "[54]\tvalid_0's binary_logloss: 0.494228\tvalid_0's auc: 0.709152\n",
      "[55]\tvalid_0's binary_logloss: 0.494147\tvalid_0's auc: 0.709138\n",
      "[56]\tvalid_0's binary_logloss: 0.494066\tvalid_0's auc: 0.70922\n",
      "[57]\tvalid_0's binary_logloss: 0.493986\tvalid_0's auc: 0.709234\n",
      "[58]\tvalid_0's binary_logloss: 0.493908\tvalid_0's auc: 0.709271\n",
      "[59]\tvalid_0's binary_logloss: 0.493836\tvalid_0's auc: 0.709327\n",
      "[60]\tvalid_0's binary_logloss: 0.493757\tvalid_0's auc: 0.709329\n",
      "[61]\tvalid_0's binary_logloss: 0.49368\tvalid_0's auc: 0.709331\n",
      "[62]\tvalid_0's binary_logloss: 0.493604\tvalid_0's auc: 0.709313\n",
      "[63]\tvalid_0's binary_logloss: 0.49353\tvalid_0's auc: 0.709296\n",
      "[64]\tvalid_0's binary_logloss: 0.493456\tvalid_0's auc: 0.709273\n",
      "[65]\tvalid_0's binary_logloss: 0.49338\tvalid_0's auc: 0.709287\n",
      "[66]\tvalid_0's binary_logloss: 0.493306\tvalid_0's auc: 0.70929\n",
      "[67]\tvalid_0's binary_logloss: 0.493233\tvalid_0's auc: 0.709261\n",
      "[68]\tvalid_0's binary_logloss: 0.49316\tvalid_0's auc: 0.709282\n",
      "[69]\tvalid_0's binary_logloss: 0.493092\tvalid_0's auc: 0.709315\n",
      "[70]\tvalid_0's binary_logloss: 0.493021\tvalid_0's auc: 0.709296\n",
      "[71]\tvalid_0's binary_logloss: 0.49295\tvalid_0's auc: 0.709275\n",
      "[72]\tvalid_0's binary_logloss: 0.492881\tvalid_0's auc: 0.70927\n",
      "[73]\tvalid_0's binary_logloss: 0.492811\tvalid_0's auc: 0.709279\n",
      "[74]\tvalid_0's binary_logloss: 0.492743\tvalid_0's auc: 0.70924\n",
      "[75]\tvalid_0's binary_logloss: 0.492677\tvalid_0's auc: 0.709249\n",
      "[76]\tvalid_0's binary_logloss: 0.492612\tvalid_0's auc: 0.70933\n",
      "[77]\tvalid_0's binary_logloss: 0.492546\tvalid_0's auc: 0.709324\n",
      "[78]\tvalid_0's binary_logloss: 0.49248\tvalid_0's auc: 0.709315\n",
      "[79]\tvalid_0's binary_logloss: 0.492417\tvalid_0's auc: 0.709313\n",
      "[80]\tvalid_0's binary_logloss: 0.492354\tvalid_0's auc: 0.709372\n",
      "[81]\tvalid_0's binary_logloss: 0.492292\tvalid_0's auc: 0.709356\n",
      "[82]\tvalid_0's binary_logloss: 0.492232\tvalid_0's auc: 0.709425\n",
      "[83]\tvalid_0's binary_logloss: 0.49217\tvalid_0's auc: 0.709433\n",
      "[84]\tvalid_0's binary_logloss: 0.492108\tvalid_0's auc: 0.709407\n",
      "[85]\tvalid_0's binary_logloss: 0.492049\tvalid_0's auc: 0.709448\n",
      "[86]\tvalid_0's binary_logloss: 0.491988\tvalid_0's auc: 0.70951\n",
      "[87]\tvalid_0's binary_logloss: 0.491929\tvalid_0's auc: 0.709539\n",
      "[88]\tvalid_0's binary_logloss: 0.49187\tvalid_0's auc: 0.709608\n",
      "[89]\tvalid_0's binary_logloss: 0.491811\tvalid_0's auc: 0.709603\n",
      "[90]\tvalid_0's binary_logloss: 0.491753\tvalid_0's auc: 0.709621\n",
      "[91]\tvalid_0's binary_logloss: 0.491695\tvalid_0's auc: 0.709627\n",
      "[92]\tvalid_0's binary_logloss: 0.491641\tvalid_0's auc: 0.709653\n",
      "[93]\tvalid_0's binary_logloss: 0.491584\tvalid_0's auc: 0.709632\n",
      "[94]\tvalid_0's binary_logloss: 0.491528\tvalid_0's auc: 0.70963\n",
      "[95]\tvalid_0's binary_logloss: 0.491472\tvalid_0's auc: 0.70963\n",
      "[96]\tvalid_0's binary_logloss: 0.491419\tvalid_0's auc: 0.709665\n",
      "[97]\tvalid_0's binary_logloss: 0.491365\tvalid_0's auc: 0.709649\n",
      "[98]\tvalid_0's binary_logloss: 0.491312\tvalid_0's auc: 0.709638\n",
      "[99]\tvalid_0's binary_logloss: 0.491277\tvalid_0's auc: 0.709891\n",
      "[100]\tvalid_0's binary_logloss: 0.491226\tvalid_0's auc: 0.709874\n",
      "[101]\tvalid_0's binary_logloss: 0.491177\tvalid_0's auc: 0.709885\n",
      "[102]\tvalid_0's binary_logloss: 0.491125\tvalid_0's auc: 0.709934\n",
      "[103]\tvalid_0's binary_logloss: 0.491074\tvalid_0's auc: 0.709918\n",
      "[104]\tvalid_0's binary_logloss: 0.491025\tvalid_0's auc: 0.709906\n",
      "[105]\tvalid_0's binary_logloss: 0.490978\tvalid_0's auc: 0.709941\n",
      "[106]\tvalid_0's binary_logloss: 0.490933\tvalid_0's auc: 0.709956\n",
      "[107]\tvalid_0's binary_logloss: 0.490886\tvalid_0's auc: 0.709957\n",
      "[108]\tvalid_0's binary_logloss: 0.490838\tvalid_0's auc: 0.709973\n",
      "[109]\tvalid_0's binary_logloss: 0.490791\tvalid_0's auc: 0.70999\n",
      "[110]\tvalid_0's binary_logloss: 0.490744\tvalid_0's auc: 0.709992\n",
      "[111]\tvalid_0's binary_logloss: 0.490696\tvalid_0's auc: 0.710005\n",
      "[112]\tvalid_0's binary_logloss: 0.490651\tvalid_0's auc: 0.71004\n",
      "[113]\tvalid_0's binary_logloss: 0.490606\tvalid_0's auc: 0.710022\n",
      "[114]\tvalid_0's binary_logloss: 0.490562\tvalid_0's auc: 0.710056\n",
      "[115]\tvalid_0's binary_logloss: 0.490518\tvalid_0's auc: 0.710057\n",
      "[116]\tvalid_0's binary_logloss: 0.490474\tvalid_0's auc: 0.710041\n",
      "[117]\tvalid_0's binary_logloss: 0.490431\tvalid_0's auc: 0.710041\n",
      "[118]\tvalid_0's binary_logloss: 0.490387\tvalid_0's auc: 0.710048\n",
      "[119]\tvalid_0's binary_logloss: 0.490347\tvalid_0's auc: 0.710065\n",
      "[120]\tvalid_0's binary_logloss: 0.490306\tvalid_0's auc: 0.710103\n",
      "[121]\tvalid_0's binary_logloss: 0.490265\tvalid_0's auc: 0.710107\n",
      "[122]\tvalid_0's binary_logloss: 0.490226\tvalid_0's auc: 0.710144\n",
      "[123]\tvalid_0's binary_logloss: 0.490186\tvalid_0's auc: 0.710195\n",
      "[124]\tvalid_0's binary_logloss: 0.490146\tvalid_0's auc: 0.710202\n",
      "[125]\tvalid_0's binary_logloss: 0.490106\tvalid_0's auc: 0.710209\n",
      "[126]\tvalid_0's binary_logloss: 0.490067\tvalid_0's auc: 0.710192\n",
      "[127]\tvalid_0's binary_logloss: 0.490031\tvalid_0's auc: 0.710209\n",
      "[128]\tvalid_0's binary_logloss: 0.489993\tvalid_0's auc: 0.710221\n",
      "[129]\tvalid_0's binary_logloss: 0.489957\tvalid_0's auc: 0.710233\n",
      "[130]\tvalid_0's binary_logloss: 0.48992\tvalid_0's auc: 0.71022\n",
      "[131]\tvalid_0's binary_logloss: 0.489883\tvalid_0's auc: 0.710253\n",
      "[132]\tvalid_0's binary_logloss: 0.489848\tvalid_0's auc: 0.710248\n",
      "[133]\tvalid_0's binary_logloss: 0.489813\tvalid_0's auc: 0.710242\n",
      "[134]\tvalid_0's binary_logloss: 0.489776\tvalid_0's auc: 0.710249\n",
      "[135]\tvalid_0's binary_logloss: 0.489741\tvalid_0's auc: 0.710271\n",
      "[136]\tvalid_0's binary_logloss: 0.489708\tvalid_0's auc: 0.710306\n",
      "[137]\tvalid_0's binary_logloss: 0.489674\tvalid_0's auc: 0.710314\n",
      "[138]\tvalid_0's binary_logloss: 0.489642\tvalid_0's auc: 0.710314\n",
      "[139]\tvalid_0's binary_logloss: 0.489608\tvalid_0's auc: 0.710307\n",
      "[140]\tvalid_0's binary_logloss: 0.489579\tvalid_0's auc: 0.710328\n",
      "[141]\tvalid_0's binary_logloss: 0.489547\tvalid_0's auc: 0.710338\n",
      "[142]\tvalid_0's binary_logloss: 0.489516\tvalid_0's auc: 0.710352\n",
      "[143]\tvalid_0's binary_logloss: 0.489486\tvalid_0's auc: 0.710353\n",
      "[144]\tvalid_0's binary_logloss: 0.489458\tvalid_0's auc: 0.71035\n",
      "[145]\tvalid_0's binary_logloss: 0.489426\tvalid_0's auc: 0.710382\n",
      "[146]\tvalid_0's binary_logloss: 0.489396\tvalid_0's auc: 0.710393\n",
      "[147]\tvalid_0's binary_logloss: 0.489368\tvalid_0's auc: 0.710436\n",
      "[148]\tvalid_0's binary_logloss: 0.489339\tvalid_0's auc: 0.710447\n",
      "[149]\tvalid_0's binary_logloss: 0.489312\tvalid_0's auc: 0.710454\n",
      "[150]\tvalid_0's binary_logloss: 0.489285\tvalid_0's auc: 0.710461\n",
      "[151]\tvalid_0's binary_logloss: 0.489258\tvalid_0's auc: 0.710451\n",
      "[152]\tvalid_0's binary_logloss: 0.489231\tvalid_0's auc: 0.710444\n",
      "[153]\tvalid_0's binary_logloss: 0.489205\tvalid_0's auc: 0.710461\n",
      "[154]\tvalid_0's binary_logloss: 0.489177\tvalid_0's auc: 0.710489\n",
      "[155]\tvalid_0's binary_logloss: 0.489151\tvalid_0's auc: 0.710521\n",
      "[156]\tvalid_0's binary_logloss: 0.489126\tvalid_0's auc: 0.710552\n",
      "[157]\tvalid_0's binary_logloss: 0.489103\tvalid_0's auc: 0.710576\n",
      "[158]\tvalid_0's binary_logloss: 0.48908\tvalid_0's auc: 0.710576\n",
      "[159]\tvalid_0's binary_logloss: 0.489055\tvalid_0's auc: 0.710582\n",
      "[160]\tvalid_0's binary_logloss: 0.489031\tvalid_0's auc: 0.710613\n",
      "[161]\tvalid_0's binary_logloss: 0.489007\tvalid_0's auc: 0.710623\n",
      "[162]\tvalid_0's binary_logloss: 0.488984\tvalid_0's auc: 0.710629\n",
      "[163]\tvalid_0's binary_logloss: 0.488961\tvalid_0's auc: 0.71066\n",
      "[164]\tvalid_0's binary_logloss: 0.488939\tvalid_0's auc: 0.710674\n",
      "[165]\tvalid_0's binary_logloss: 0.488918\tvalid_0's auc: 0.710661\n",
      "[166]\tvalid_0's binary_logloss: 0.488898\tvalid_0's auc: 0.710652\n",
      "[167]\tvalid_0's binary_logloss: 0.488877\tvalid_0's auc: 0.710667\n",
      "[168]\tvalid_0's binary_logloss: 0.488856\tvalid_0's auc: 0.710679\n",
      "[169]\tvalid_0's binary_logloss: 0.488836\tvalid_0's auc: 0.710692\n",
      "[170]\tvalid_0's binary_logloss: 0.488817\tvalid_0's auc: 0.710713\n",
      "[171]\tvalid_0's binary_logloss: 0.488798\tvalid_0's auc: 0.710726\n",
      "[172]\tvalid_0's binary_logloss: 0.488779\tvalid_0's auc: 0.710736\n",
      "[173]\tvalid_0's binary_logloss: 0.488761\tvalid_0's auc: 0.710782\n",
      "[174]\tvalid_0's binary_logloss: 0.488744\tvalid_0's auc: 0.710796\n",
      "[175]\tvalid_0's binary_logloss: 0.488727\tvalid_0's auc: 0.710807\n",
      "[176]\tvalid_0's binary_logloss: 0.48871\tvalid_0's auc: 0.710814\n",
      "[177]\tvalid_0's binary_logloss: 0.488694\tvalid_0's auc: 0.710825\n",
      "[178]\tvalid_0's binary_logloss: 0.488679\tvalid_0's auc: 0.71085\n",
      "[179]\tvalid_0's binary_logloss: 0.488663\tvalid_0's auc: 0.710854\n",
      "[180]\tvalid_0's binary_logloss: 0.488646\tvalid_0's auc: 0.710865\n",
      "[181]\tvalid_0's binary_logloss: 0.488631\tvalid_0's auc: 0.710853\n",
      "[182]\tvalid_0's binary_logloss: 0.488616\tvalid_0's auc: 0.710864\n",
      "[183]\tvalid_0's binary_logloss: 0.488601\tvalid_0's auc: 0.710875\n",
      "[184]\tvalid_0's binary_logloss: 0.488587\tvalid_0's auc: 0.710873\n",
      "[185]\tvalid_0's binary_logloss: 0.488574\tvalid_0's auc: 0.710877\n",
      "[186]\tvalid_0's binary_logloss: 0.488561\tvalid_0's auc: 0.71089\n",
      "[187]\tvalid_0's binary_logloss: 0.488549\tvalid_0's auc: 0.710899\n",
      "[188]\tvalid_0's binary_logloss: 0.488537\tvalid_0's auc: 0.710913\n",
      "[189]\tvalid_0's binary_logloss: 0.488525\tvalid_0's auc: 0.710942\n",
      "[190]\tvalid_0's binary_logloss: 0.488513\tvalid_0's auc: 0.710948\n",
      "[191]\tvalid_0's binary_logloss: 0.488501\tvalid_0's auc: 0.710956\n",
      "[192]\tvalid_0's binary_logloss: 0.488491\tvalid_0's auc: 0.710986\n",
      "[193]\tvalid_0's binary_logloss: 0.488481\tvalid_0's auc: 0.711007\n",
      "[194]\tvalid_0's binary_logloss: 0.488471\tvalid_0's auc: 0.711016\n",
      "[195]\tvalid_0's binary_logloss: 0.488462\tvalid_0's auc: 0.711046\n",
      "[196]\tvalid_0's binary_logloss: 0.488453\tvalid_0's auc: 0.711053\n",
      "[197]\tvalid_0's binary_logloss: 0.488443\tvalid_0's auc: 0.711063\n",
      "[198]\tvalid_0's binary_logloss: 0.488434\tvalid_0's auc: 0.71109\n",
      "[199]\tvalid_0's binary_logloss: 0.488427\tvalid_0's auc: 0.7111\n",
      "[200]\tvalid_0's binary_logloss: 0.488418\tvalid_0's auc: 0.71111\n",
      "[201]\tvalid_0's binary_logloss: 0.488411\tvalid_0's auc: 0.711123\n",
      "[202]\tvalid_0's binary_logloss: 0.488405\tvalid_0's auc: 0.71115\n",
      "[203]\tvalid_0's binary_logloss: 0.488398\tvalid_0's auc: 0.711156\n",
      "[204]\tvalid_0's binary_logloss: 0.48839\tvalid_0's auc: 0.711173\n",
      "[205]\tvalid_0's binary_logloss: 0.488383\tvalid_0's auc: 0.711178\n",
      "[206]\tvalid_0's binary_logloss: 0.488376\tvalid_0's auc: 0.711195\n",
      "[207]\tvalid_0's binary_logloss: 0.488371\tvalid_0's auc: 0.711198\n",
      "[208]\tvalid_0's binary_logloss: 0.488366\tvalid_0's auc: 0.711224\n",
      "[209]\tvalid_0's binary_logloss: 0.48836\tvalid_0's auc: 0.711238\n",
      "[210]\tvalid_0's binary_logloss: 0.488355\tvalid_0's auc: 0.711263\n",
      "[211]\tvalid_0's binary_logloss: 0.488351\tvalid_0's auc: 0.71127\n",
      "[212]\tvalid_0's binary_logloss: 0.488348\tvalid_0's auc: 0.711291\n",
      "[213]\tvalid_0's binary_logloss: 0.488347\tvalid_0's auc: 0.711295\n",
      "[214]\tvalid_0's binary_logloss: 0.488343\tvalid_0's auc: 0.711306\n",
      "[215]\tvalid_0's binary_logloss: 0.48834\tvalid_0's auc: 0.711315\n",
      "[216]\tvalid_0's binary_logloss: 0.488336\tvalid_0's auc: 0.711324\n",
      "[217]\tvalid_0's binary_logloss: 0.488335\tvalid_0's auc: 0.711346\n",
      "[218]\tvalid_0's binary_logloss: 0.488333\tvalid_0's auc: 0.71135\n",
      "[219]\tvalid_0's binary_logloss: 0.488332\tvalid_0's auc: 0.711365\n",
      "[220]\tvalid_0's binary_logloss: 0.488333\tvalid_0's auc: 0.711385\n",
      "[221]\tvalid_0's binary_logloss: 0.488331\tvalid_0's auc: 0.711399\n",
      "[222]\tvalid_0's binary_logloss: 0.488329\tvalid_0's auc: 0.711411\n",
      "[223]\tvalid_0's binary_logloss: 0.488328\tvalid_0's auc: 0.711412\n",
      "[224]\tvalid_0's binary_logloss: 0.488329\tvalid_0's auc: 0.71143\n",
      "[225]\tvalid_0's binary_logloss: 0.488328\tvalid_0's auc: 0.711452\n",
      "[226]\tvalid_0's binary_logloss: 0.488327\tvalid_0's auc: 0.711471\n",
      "[227]\tvalid_0's binary_logloss: 0.488329\tvalid_0's auc: 0.711481\n",
      "[228]\tvalid_0's binary_logloss: 0.48833\tvalid_0's auc: 0.711477\n",
      "[229]\tvalid_0's binary_logloss: 0.488332\tvalid_0's auc: 0.711494\n",
      "[230]\tvalid_0's binary_logloss: 0.488334\tvalid_0's auc: 0.711498\n",
      "[231]\tvalid_0's binary_logloss: 0.488335\tvalid_0's auc: 0.711507\n",
      "[232]\tvalid_0's binary_logloss: 0.488338\tvalid_0's auc: 0.711507\n",
      "[233]\tvalid_0's binary_logloss: 0.488339\tvalid_0's auc: 0.711515\n",
      "[234]\tvalid_0's binary_logloss: 0.488341\tvalid_0's auc: 0.711521\n",
      "[235]\tvalid_0's binary_logloss: 0.488344\tvalid_0's auc: 0.711545\n",
      "[236]\tvalid_0's binary_logloss: 0.488347\tvalid_0's auc: 0.711568\n",
      "[237]\tvalid_0's binary_logloss: 0.488352\tvalid_0's auc: 0.711593\n",
      "[238]\tvalid_0's binary_logloss: 0.488355\tvalid_0's auc: 0.711606\n",
      "[239]\tvalid_0's binary_logloss: 0.488361\tvalid_0's auc: 0.71162\n",
      "[240]\tvalid_0's binary_logloss: 0.488366\tvalid_0's auc: 0.711631\n",
      "[241]\tvalid_0's binary_logloss: 0.488369\tvalid_0's auc: 0.711647\n",
      "[242]\tvalid_0's binary_logloss: 0.488375\tvalid_0's auc: 0.711655\n",
      "[243]\tvalid_0's binary_logloss: 0.48838\tvalid_0's auc: 0.711668\n",
      "[244]\tvalid_0's binary_logloss: 0.488385\tvalid_0's auc: 0.71168\n",
      "[245]\tvalid_0's binary_logloss: 0.488392\tvalid_0's auc: 0.711683\n",
      "[246]\tvalid_0's binary_logloss: 0.488397\tvalid_0's auc: 0.711695\n",
      "[247]\tvalid_0's binary_logloss: 0.488404\tvalid_0's auc: 0.711701\n",
      "[248]\tvalid_0's binary_logloss: 0.488411\tvalid_0's auc: 0.711708\n",
      "[249]\tvalid_0's binary_logloss: 0.488417\tvalid_0's auc: 0.711718\n",
      "[250]\tvalid_0's binary_logloss: 0.488426\tvalid_0's auc: 0.711741\n",
      "[251]\tvalid_0's binary_logloss: 0.488434\tvalid_0's auc: 0.71176\n",
      "[252]\tvalid_0's binary_logloss: 0.488442\tvalid_0's auc: 0.71178\n",
      "[253]\tvalid_0's binary_logloss: 0.48845\tvalid_0's auc: 0.71181\n",
      "[254]\tvalid_0's binary_logloss: 0.488459\tvalid_0's auc: 0.711813\n",
      "[255]\tvalid_0's binary_logloss: 0.488468\tvalid_0's auc: 0.711826\n",
      "[256]\tvalid_0's binary_logloss: 0.488477\tvalid_0's auc: 0.711852\n",
      "[257]\tvalid_0's binary_logloss: 0.488486\tvalid_0's auc: 0.711863\n",
      "[258]\tvalid_0's binary_logloss: 0.488496\tvalid_0's auc: 0.711882\n",
      "[259]\tvalid_0's binary_logloss: 0.488514\tvalid_0's auc: 0.711958\n",
      "[260]\tvalid_0's binary_logloss: 0.488524\tvalid_0's auc: 0.711964\n",
      "[261]\tvalid_0's binary_logloss: 0.488532\tvalid_0's auc: 0.711985\n",
      "[262]\tvalid_0's binary_logloss: 0.488541\tvalid_0's auc: 0.712013\n",
      "[263]\tvalid_0's binary_logloss: 0.488551\tvalid_0's auc: 0.712029\n",
      "[264]\tvalid_0's binary_logloss: 0.488563\tvalid_0's auc: 0.712044\n",
      "[265]\tvalid_0's binary_logloss: 0.488573\tvalid_0's auc: 0.712067\n",
      "[266]\tvalid_0's binary_logloss: 0.488585\tvalid_0's auc: 0.712079\n",
      "[267]\tvalid_0's binary_logloss: 0.488596\tvalid_0's auc: 0.712082\n",
      "[268]\tvalid_0's binary_logloss: 0.488607\tvalid_0's auc: 0.71209\n",
      "[269]\tvalid_0's binary_logloss: 0.48862\tvalid_0's auc: 0.712098\n",
      "[270]\tvalid_0's binary_logloss: 0.488634\tvalid_0's auc: 0.712093\n",
      "[271]\tvalid_0's binary_logloss: 0.488647\tvalid_0's auc: 0.712106\n",
      "[272]\tvalid_0's binary_logloss: 0.48866\tvalid_0's auc: 0.712114\n",
      "[273]\tvalid_0's binary_logloss: 0.488676\tvalid_0's auc: 0.712124\n",
      "[274]\tvalid_0's binary_logloss: 0.488689\tvalid_0's auc: 0.71214\n",
      "[275]\tvalid_0's binary_logloss: 0.488702\tvalid_0's auc: 0.71215\n",
      "[276]\tvalid_0's binary_logloss: 0.488717\tvalid_0's auc: 0.712153\n",
      "[277]\tvalid_0's binary_logloss: 0.488731\tvalid_0's auc: 0.712165\n",
      "[278]\tvalid_0's binary_logloss: 0.488745\tvalid_0's auc: 0.712176\n",
      "[279]\tvalid_0's binary_logloss: 0.488759\tvalid_0's auc: 0.71219\n",
      "[280]\tvalid_0's binary_logloss: 0.488773\tvalid_0's auc: 0.712193\n",
      "[281]\tvalid_0's binary_logloss: 0.48879\tvalid_0's auc: 0.712198\n",
      "[282]\tvalid_0's binary_logloss: 0.488805\tvalid_0's auc: 0.712219\n",
      "[283]\tvalid_0's binary_logloss: 0.488821\tvalid_0's auc: 0.71224\n",
      "[284]\tvalid_0's binary_logloss: 0.488837\tvalid_0's auc: 0.712245\n",
      "[285]\tvalid_0's binary_logloss: 0.488853\tvalid_0's auc: 0.712249\n",
      "[286]\tvalid_0's binary_logloss: 0.488871\tvalid_0's auc: 0.712256\n",
      "[287]\tvalid_0's binary_logloss: 0.488887\tvalid_0's auc: 0.712265\n",
      "[288]\tvalid_0's binary_logloss: 0.488903\tvalid_0's auc: 0.712272\n",
      "[289]\tvalid_0's binary_logloss: 0.48892\tvalid_0's auc: 0.712284\n",
      "[290]\tvalid_0's binary_logloss: 0.488938\tvalid_0's auc: 0.712304\n",
      "[291]\tvalid_0's binary_logloss: 0.488954\tvalid_0's auc: 0.712312\n",
      "[292]\tvalid_0's binary_logloss: 0.488972\tvalid_0's auc: 0.712314\n",
      "[293]\tvalid_0's binary_logloss: 0.488989\tvalid_0's auc: 0.712322\n",
      "[294]\tvalid_0's binary_logloss: 0.489007\tvalid_0's auc: 0.712344\n",
      "[295]\tvalid_0's binary_logloss: 0.489026\tvalid_0's auc: 0.712353\n",
      "[296]\tvalid_0's binary_logloss: 0.489043\tvalid_0's auc: 0.712367\n",
      "[297]\tvalid_0's binary_logloss: 0.489062\tvalid_0's auc: 0.712385\n",
      "[298]\tvalid_0's binary_logloss: 0.48908\tvalid_0's auc: 0.712397\n",
      "[299]\tvalid_0's binary_logloss: 0.489099\tvalid_0's auc: 0.712412\n",
      "[300]\tvalid_0's binary_logloss: 0.48912\tvalid_0's auc: 0.712418\n",
      "[301]\tvalid_0's binary_logloss: 0.489138\tvalid_0's auc: 0.712433\n",
      "[302]\tvalid_0's binary_logloss: 0.489158\tvalid_0's auc: 0.712438\n",
      "[303]\tvalid_0's binary_logloss: 0.489178\tvalid_0's auc: 0.712444\n",
      "[304]\tvalid_0's binary_logloss: 0.4892\tvalid_0's auc: 0.712449\n",
      "[305]\tvalid_0's binary_logloss: 0.48922\tvalid_0's auc: 0.712453\n",
      "[306]\tvalid_0's binary_logloss: 0.489242\tvalid_0's auc: 0.712462\n",
      "[307]\tvalid_0's binary_logloss: 0.489262\tvalid_0's auc: 0.712472\n",
      "[308]\tvalid_0's binary_logloss: 0.489285\tvalid_0's auc: 0.712479\n",
      "[309]\tvalid_0's binary_logloss: 0.489307\tvalid_0's auc: 0.71249\n",
      "[310]\tvalid_0's binary_logloss: 0.48933\tvalid_0's auc: 0.712496\n",
      "[311]\tvalid_0's binary_logloss: 0.48935\tvalid_0's auc: 0.712512\n",
      "[312]\tvalid_0's binary_logloss: 0.489372\tvalid_0's auc: 0.712532\n",
      "[313]\tvalid_0's binary_logloss: 0.489395\tvalid_0's auc: 0.71253\n",
      "[314]\tvalid_0's binary_logloss: 0.489415\tvalid_0's auc: 0.71254\n",
      "[315]\tvalid_0's binary_logloss: 0.489437\tvalid_0's auc: 0.712547\n",
      "[316]\tvalid_0's binary_logloss: 0.48946\tvalid_0's auc: 0.712555\n",
      "[317]\tvalid_0's binary_logloss: 0.489483\tvalid_0's auc: 0.712553\n",
      "[318]\tvalid_0's binary_logloss: 0.489507\tvalid_0's auc: 0.712553\n",
      "[319]\tvalid_0's binary_logloss: 0.48953\tvalid_0's auc: 0.712557\n",
      "[320]\tvalid_0's binary_logloss: 0.489554\tvalid_0's auc: 0.712564\n",
      "[321]\tvalid_0's binary_logloss: 0.489576\tvalid_0's auc: 0.71257\n",
      "[322]\tvalid_0's binary_logloss: 0.4896\tvalid_0's auc: 0.712581\n",
      "[323]\tvalid_0's binary_logloss: 0.489624\tvalid_0's auc: 0.712595\n",
      "[324]\tvalid_0's binary_logloss: 0.489648\tvalid_0's auc: 0.712599\n",
      "[325]\tvalid_0's binary_logloss: 0.489673\tvalid_0's auc: 0.712608\n",
      "[326]\tvalid_0's binary_logloss: 0.489697\tvalid_0's auc: 0.71262\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.488327\tvalid_0's auc: 0.711471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',\n",
       "               cat_smooth=0, class_weight=None, colsample_bytree=1.0,\n",
       "               feature_fraction=0.8, importance_type='split',\n",
       "               learning_rate=0.001, max_depth=6, metric='binary_logloss,auc',\n",
       "               min_child_samples=19, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=1000, n_jobs=-1, num_leaves=50, objective='binary',\n",
       "               random_state=None, reg_alpha=0.01, reg_lambda=75,\n",
       "               scale_pos_weight=4, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ex.fit(X_train, y_train, eval_set=(X_eval, y_eval), \r\n",
    "           categorical_feature=categorical_fea, \r\n",
    "           early_stopping_rounds = 100\r\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8004875\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_ex.predict(X_eval)\r\n",
    "print(accuracy_score(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_eval, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb40d4358d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x1296 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,18))\r\n",
    "lgb.plot_importance(clf_ex, max_num_features=30, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf_ex.predict_proba(X_testA)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/lgbm/clf_ex_参数调优版.pkl', 'wb') as file:\r\n",
    "    pickle.dump(clf_ex, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.251652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.179927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.224783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.262463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>0.272591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>0.284886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.298462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.318601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.319229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  200000.000000\n",
       "mean        0.251652\n",
       "std         0.034907\n",
       "min         0.179927\n",
       "25%         0.224783\n",
       "50%         0.253288\n",
       "60%         0.262463\n",
       "70%         0.272591\n",
       "80%         0.284886\n",
       "90%         0.298462\n",
       "99%         0.318601\n",
       "max         0.319229"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred).describe(percentiles=[0.25,0.5,0.6,0.7,0.8,0.9,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {'id' : testA.index, 'isDefault' : pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id' : X_testA.index, 'isDefault' : pred})\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x > 0 else 0)\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x < 1 else 1)\r\n",
    "submission.to_csv('./work/lgbm/submission_lgb_参数调优版.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用五折交叉验证的LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\r\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#准备数据\r\n",
    "X_train = pd.concat((X_train, X_eval))\r\n",
    "y_train = y_train.append(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_lgb = {\r\n",
    "    'objective': 'binary', 'metric':  'binary_logloss,auc',\r\n",
    "    'max_depth': 6, 'num_leaves': 50,\r\n",
    "    'min_child_samples': 18, 'min_child_weight': 0.001,\r\n",
    "    'feature_fraction': 0.8,\r\n",
    "    'bagging_fraction': 0.9, 'bagging_freq': 2,\r\n",
    "    'reg_alpha': 1e-05, 'reg_lambda': 80,\r\n",
    "    'cat_smooth': 0\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NFOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = NFOLD, shuffle = True, random_state = 200)\r\n",
    "# kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\r\n",
    "pred = np.zeros(len(X_testA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?lgb.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 127605, number of negative: 512395\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4060\n",
      "[LightGBM] [Info] Number of data points in the train set: 640000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.199383 -> initscore=-1.390156\n",
      "[LightGBM] [Info] Start training from score -1.390156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.500687\tvalid_0's auc: 0.500898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's binary_logloss: 0.500858\tvalid_0's auc: 0.502916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's binary_logloss: 0.501156\tvalid_0's auc: 0.501999\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.501396\tvalid_0's auc: 0.502651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tvalid_0's binary_logloss: 0.501682\tvalid_0's auc: 0.502887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's binary_logloss: 0.501974\tvalid_0's auc: 0.502926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's binary_logloss: 0.50225\tvalid_0's auc: 0.502635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's binary_logloss: 0.502471\tvalid_0's auc: 0.502792\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's binary_logloss: 0.502719\tvalid_0's auc: 0.503091\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's binary_logloss: 0.502965\tvalid_0's auc: 0.503046\n",
      "[LightGBM] [Info] Number of positive: 127591, number of negative: 512409\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.537446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4067\n",
      "[LightGBM] [Info] Number of data points in the train set: 640000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.199361 -> initscore=-1.390293\n",
      "[LightGBM] [Info] Start training from score -1.390293\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.500945\tvalid_0's auc: 0.497613\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's binary_logloss: 0.501243\tvalid_0's auc: 0.497643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's binary_logloss: 0.501618\tvalid_0's auc: 0.497052\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.501895\tvalid_0's auc: 0.497967\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tvalid_0's binary_logloss: 0.502206\tvalid_0's auc: 0.498214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's binary_logloss: 0.502458\tvalid_0's auc: 0.498914\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's binary_logloss: 0.502827\tvalid_0's auc: 0.498022\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's binary_logloss: 0.503091\tvalid_0's auc: 0.498685\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's binary_logloss: 0.503338\tvalid_0's auc: 0.499389\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's binary_logloss: 0.503722\tvalid_0's auc: 0.498529\n",
      "[LightGBM] [Info] Number of positive: 127783, number of negative: 512217\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4062\n",
      "[LightGBM] [Info] Number of data points in the train set: 640000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.199661 -> initscore=-1.388415\n",
      "[LightGBM] [Info] Start training from score -1.388415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.499232\tvalid_0's auc: 0.498274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's binary_logloss: 0.499538\tvalid_0's auc: 0.497643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's binary_logloss: 0.499878\tvalid_0's auc: 0.497041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.500091\tvalid_0's auc: 0.498018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tvalid_0's binary_logloss: 0.500367\tvalid_0's auc: 0.499084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's binary_logloss: 0.500706\tvalid_0's auc: 0.498738\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's binary_logloss: 0.500979\tvalid_0's auc: 0.499341\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's binary_logloss: 0.501264\tvalid_0's auc: 0.499123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's binary_logloss: 0.501499\tvalid_0's auc: 0.500115\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's binary_logloss: 0.501739\tvalid_0's auc: 0.500544\n",
      "[LightGBM] [Info] Number of positive: 127645, number of negative: 512355\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.543570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4044\n",
      "[LightGBM] [Info] Number of data points in the train set: 640000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.199445 -> initscore=-1.389765\n",
      "[LightGBM] [Info] Start training from score -1.389765\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.500332\tvalid_0's auc: 0.50014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's binary_logloss: 0.500649\tvalid_0's auc: 0.499816\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's binary_logloss: 0.500954\tvalid_0's auc: 0.499485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.50126\tvalid_0's auc: 0.499131\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tvalid_0's binary_logloss: 0.501513\tvalid_0's auc: 0.499282\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's binary_logloss: 0.501788\tvalid_0's auc: 0.500119\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's binary_logloss: 0.50202\tvalid_0's auc: 0.500744\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's binary_logloss: 0.502271\tvalid_0's auc: 0.50099\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's binary_logloss: 0.502557\tvalid_0's auc: 0.501383\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's binary_logloss: 0.502818\tvalid_0's auc: 0.501948\n",
      "[LightGBM] [Info] Number of positive: 127816, number of negative: 512184\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.161750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4048\n",
      "[LightGBM] [Info] Number of data points in the train set: 640000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.199712 -> initscore=-1.388092\n",
      "[LightGBM] [Info] Start training from score -1.388092\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.498888\tvalid_0's auc: 0.499683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's binary_logloss: 0.499178\tvalid_0's auc: 0.499689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's binary_logloss: 0.499483\tvalid_0's auc: 0.49965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.499776\tvalid_0's auc: 0.500139\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tvalid_0's binary_logloss: 0.5\tvalid_0's auc: 0.500676\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's binary_logloss: 0.500269\tvalid_0's auc: 0.500706\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's binary_logloss: 0.500592\tvalid_0's auc: 0.500186\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's binary_logloss: 0.500889\tvalid_0's auc: 0.500307\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's binary_logloss: 0.501198\tvalid_0's auc: 0.499971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's binary_logloss: 0.501474\tvalid_0's auc: 0.500047\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\r\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_index, :], X_train.iloc[val_index, :]\r\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\r\n",
    "    train_set = lgb.Dataset(X_fold_train, y_fold_train)\r\n",
    "    val_set = lgb.Dataset(X_fold_val, y_fold_val, reference=train_set)\r\n",
    "\r\n",
    "    model = lgb.train(params_lgb, train_set, num_boost_round=1000, #early_stopping_rounds=50,\r\n",
    "                      valid_sets = val_set, verbose_eval=100)\r\n",
    "\r\n",
    "    pred += model.predict(X_testA, num_iteration=model.best_iteration)/kf.n_splits\r\n",
    "\r\n",
    "# y_pred = [1 if y > 0.5 else 0 for y in y_pred]\r\n",
    "# rmse = metrics.accuracy_score(y_pred,y_test)\r\n",
    "# print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.398802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.277897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.383904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.398033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.403437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>0.409320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>0.416616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.427824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.463992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.609617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  200000.000000\n",
       "mean        0.398802\n",
       "std         0.023917\n",
       "min         0.277897\n",
       "25%         0.383904\n",
       "50%         0.398033\n",
       "60%         0.403437\n",
       "70%         0.409320\n",
       "80%         0.416616\n",
       "90%         0.427824\n",
       "99%         0.463992\n",
       "max         0.609617"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred).describe(percentiles=[0.25,0.5,0.6,0.7,0.8,0.9,.99])\r\n",
    "# pred[pred > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/cv_lgbm/cv_lgbm.pkl', 'wb') as file:\r\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id' : X_testA.index, 'isDefault' : pred})\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x > 0 else 0)\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x < 1 else 1)\r\n",
    "submission.to_csv('./work/cv_lgbm/submission_cvlgb.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data_lgb = lgb.Dataset(X_train, y_train, silent=True)\r\n",
    "\r\n",
    "# cv_results = lgb.cv(\r\n",
    "#     params_lgb, train_data_lgb, num_boost_round=1000, nfold=5, stratified=False, shuffle=False, \r\n",
    "#     early_stopping_rounds=10, verbose_eval=50, show_stdv=True, seed=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用CatBoost 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !mkdir /home/aistudio/external-libraries\r\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries\r\n",
    "# !pip install catboost -i https://pypi.tuna.tsinghua.edu.cn/simple -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 标记分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?cb.CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_model = cb.CatBoostClassifier(iterations=2000, depth=7, learning_rate=0.001, loss_function='Logloss', eval_metric='AUC', metric_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?cat_model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6953417\tbest: 0.6953417 (0)\ttotal: 264ms\tremaining: 8m 47s\n",
      "100:\ttest: 0.7101377\tbest: 0.7101377 (100)\ttotal: 15.9s\tremaining: 4m 59s\n",
      "200:\ttest: 0.7107022\tbest: 0.7107022 (200)\ttotal: 31.7s\tremaining: 4m 43s\n",
      "300:\ttest: 0.7112396\tbest: 0.7112396 (300)\ttotal: 48.1s\tremaining: 4m 31s\n",
      "400:\ttest: 0.7118122\tbest: 0.7118122 (400)\ttotal: 1m 4s\tremaining: 4m 17s\n",
      "500:\ttest: 0.7123503\tbest: 0.7123503 (500)\ttotal: 1m 20s\tremaining: 4m\n",
      "600:\ttest: 0.7129757\tbest: 0.7129757 (600)\ttotal: 1m 36s\tremaining: 3m 44s\n",
      "700:\ttest: 0.7135453\tbest: 0.7135453 (700)\ttotal: 1m 52s\tremaining: 3m 29s\n",
      "800:\ttest: 0.7141596\tbest: 0.7141596 (800)\ttotal: 2m 8s\tremaining: 3m 12s\n",
      "900:\ttest: 0.7147863\tbest: 0.7147863 (900)\ttotal: 2m 24s\tremaining: 2m 56s\n",
      "1000:\ttest: 0.7153816\tbest: 0.7153816 (1000)\ttotal: 2m 40s\tremaining: 2m 40s\n",
      "1100:\ttest: 0.7159762\tbest: 0.7159762 (1100)\ttotal: 2m 56s\tremaining: 2m 23s\n",
      "1200:\ttest: 0.7165293\tbest: 0.7165293 (1200)\ttotal: 3m 13s\tremaining: 2m 8s\n",
      "1300:\ttest: 0.7171058\tbest: 0.7171058 (1300)\ttotal: 3m 28s\tremaining: 1m 52s\n",
      "1400:\ttest: 0.7176115\tbest: 0.7176115 (1400)\ttotal: 3m 44s\tremaining: 1m 36s\n",
      "1500:\ttest: 0.7181553\tbest: 0.7181553 (1500)\ttotal: 4m 1s\tremaining: 1m 20s\n",
      "1600:\ttest: 0.7185985\tbest: 0.7185985 (1600)\ttotal: 4m 17s\tremaining: 1m 4s\n",
      "1700:\ttest: 0.7190394\tbest: 0.7190394 (1700)\ttotal: 4m 33s\tremaining: 48s\n",
      "1800:\ttest: 0.7194650\tbest: 0.7194650 (1800)\ttotal: 4m 49s\tremaining: 31.9s\n",
      "1900:\ttest: 0.7198985\tbest: 0.7198985 (1900)\ttotal: 5m 5s\tremaining: 15.9s\n",
      "1999:\ttest: 0.7203076\tbest: 0.7203076 (1999)\ttotal: 5m 20s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7203076205\n",
      "bestIteration = 1999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f19fc900110>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(X_train, y_train, eval_set=(X_eval, y_eval),verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80331875\n"
     ]
    }
   ],
   "source": [
    "y_pred = cat_model.predict(X_eval)\r\n",
    "print(accuracy_score(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139742945401401"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_eval, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.29844384e-01, 1.35444392e+01, 1.30410763e+01, 8.15818310e-01,\n",
       "       1.54091412e+01, 2.28591942e+01, 2.97123438e-01, 1.17086455e+00,\n",
       "       6.87194450e+00, 2.47041691e+00, 5.03326017e-01, 9.52872725e-03,\n",
       "       1.37649297e-02, 1.05959176e-02, 4.15134737e+00, 9.59488281e-03,\n",
       "       2.53836146e+00, 2.71321455e+00, 1.38579051e-02, 6.08530621e-03,\n",
       "       6.81123289e-03, 2.74251200e-01, 7.69585810e-02, 3.73667760e-02,\n",
       "       1.19066814e-02, 4.96410988e-03, 2.65061640e-01, 0.00000000e+00,\n",
       "       4.66142957e-03, 5.61442838e-02, 5.54689815e-01, 7.25162367e-01,\n",
       "       2.86460655e-02, 1.18928289e-02, 1.83732386e-02, 3.66414746e-02,\n",
       "       1.34146004e-02, 4.68281187e-01, 1.82287849e-02, 1.55109376e-01,\n",
       "       1.18609767e-02, 9.63022463e-03, 3.69784642e-01, 3.56794433e+00,\n",
       "       1.24512162e-02, 5.75988062e+00, 2.43602383e-02, 7.22258274e-03,\n",
       "       8.87594906e-02])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = cat_model.predict_proba(X_testA)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.103802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.049007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.207666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.237213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>0.270913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>0.313829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.376757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.501761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.625384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  200000.000000\n",
       "mean        0.225393\n",
       "std         0.103802\n",
       "min         0.049007\n",
       "25%         0.141100\n",
       "50%         0.207666\n",
       "60%         0.237213\n",
       "70%         0.270913\n",
       "80%         0.313829\n",
       "90%         0.376757\n",
       "99%         0.501761\n",
       "max         0.625384"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred).describe(percentiles=[0.25,0.5,0.6,0.7,0.8,0.9,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/catboost/cat_model.pkl', 'wb') as file:\r\n",
    "    pickle.dump(cat_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id' : X_testA.index, 'isDefault' : pred})\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x > 0 else 0)\r\n",
    "submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x < 1 else 1)\r\n",
    "submission.to_csv('./work/catboost/submission_cb.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用五折交叉验证的CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\r\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_X = X_train.copy()\r\n",
    "data_y = y_train.copy()\r\n",
    "data_X_eval = X_eval.copy()\r\n",
    "data_X_testA = X_testA.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 标记分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verificationStatus',\n",
       " 'policyCode',\n",
       " 'applicationType',\n",
       " 'title',\n",
       " 'initialListStatus',\n",
       " 'postCode',\n",
       " 'regionCode',\n",
       " 'employmentTitle',\n",
       " 'purpose',\n",
       " 'homeOwnership']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.columns\r\n",
    "categorical_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data_X.columns:\r\n",
    "    if i in categorical_fea:\r\n",
    "        data_X[i] = data_X[i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data_X_eval.columns:\r\n",
    "    if i in categorical_fea:\r\n",
    "        data_X_eval[i] = data_X_eval[i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data_X_testA.columns:\r\n",
    "    if i in categorical_fea:\r\n",
    "        data_X_testA[i] = data_X_testA[i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_X[data_y['isDefault']== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#尝试增加isDefault=1的样本数量\r\n",
    "data_X = pd.concat((data_X, data_X[data_y['isDefault']== 1], data_X[data_y['isDefault']== 1]))\r\n",
    "\r\n",
    "data_y = pd.concat((data_y, pd.DataFrame(np.ones(data_y[data_y['isDefault']== 1].shape[0] * 2), columns = ['isDefault']).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_cat_model = cb.CatBoostClassifier(loss_function='Logloss', eval_metric='AUC', \r\n",
    "                                  iterations=500, depth=7, learning_rate=0.1, \r\n",
    "                                  random_state=2020, od_type=\"Iter\",\r\n",
    "                                  bagging_temperature=0.5, sampling_frequency='PerTree', sampling_unit='Object',\r\n",
    "                                  colsample_bylevel=0.8,\r\n",
    "                                  metric_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs = []\r\n",
    "answers = []\r\n",
    "answers_eval = []\r\n",
    "mean_score = 0\r\n",
    "NFOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6971059\tbest: 0.6971059 (0)\ttotal: 1.26s\tremaining: 10m 29s\n",
      "100:\ttest: 0.9868819\tbest: 0.9868819 (100)\ttotal: 2m 3s\tremaining: 8m 7s\n",
      "200:\ttest: 0.9876863\tbest: 0.9876863 (200)\ttotal: 4m 5s\tremaining: 6m 5s\n",
      "300:\ttest: 0.9880280\tbest: 0.9880293 (296)\ttotal: 6m 4s\tremaining: 4m\n",
      "400:\ttest: 0.9883329\tbest: 0.9883371 (383)\ttotal: 8m 1s\tremaining: 1m 58s\n",
      "499:\ttest: 0.9884519\tbest: 0.9884561 (494)\ttotal: 9m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9884561139\n",
      "bestIteration = 494\n",
      "\n",
      "Shrink model to first 495 iterations.\n",
      "cat验证的auc:0.9884561138627751\n",
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7011966\tbest: 0.7011966 (0)\ttotal: 1.05s\tremaining: 8m 44s\n",
      "100:\ttest: 0.9862103\tbest: 0.9862103 (100)\ttotal: 2m\tremaining: 7m 55s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.9863460776\n",
      "bestIteration = 130\n",
      "\n",
      "Shrink model to first 131 iterations.\n",
      "cat验证的auc:0.9863460775990877\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7017652\tbest: 0.7017652 (0)\ttotal: 996ms\tremaining: 8m 16s\n",
      "100:\ttest: 0.9862145\tbest: 0.9862152 (99)\ttotal: 2m 2s\tremaining: 8m 5s\n",
      "200:\ttest: 0.9870128\tbest: 0.9870128 (200)\ttotal: 4m 2s\tremaining: 6m\n",
      "300:\ttest: 0.9874707\tbest: 0.9874795 (292)\ttotal: 6m\tremaining: 3m 58s\n",
      "400:\ttest: 0.9876298\tbest: 0.9876298 (400)\ttotal: 7m 59s\tremaining: 1m 58s\n",
      "499:\ttest: 0.9878354\tbest: 0.9878362 (498)\ttotal: 9m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9878361691\n",
      "bestIteration = 498\n",
      "\n",
      "Shrink model to first 499 iterations.\n",
      "cat验证的auc:0.9878361691163197\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7020554\tbest: 0.7020554 (0)\ttotal: 979ms\tremaining: 8m 8s\n",
      "100:\ttest: 0.9861101\tbest: 0.9861209 (94)\ttotal: 2m 2s\tremaining: 8m 2s\n",
      "200:\ttest: 0.9866262\tbest: 0.9866329 (198)\ttotal: 3m 55s\tremaining: 5m 50s\n",
      "300:\ttest: 0.9869858\tbest: 0.9869858 (300)\ttotal: 5m 49s\tremaining: 3m 50s\n",
      "400:\ttest: 0.9871808\tbest: 0.9871808 (400)\ttotal: 7m 44s\tremaining: 1m 54s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.9872104644\n",
      "bestIteration = 429\n",
      "\n",
      "Shrink model to first 430 iterations.\n",
      "cat验证的auc:0.9872104643645006\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6997155\tbest: 0.6997155 (0)\ttotal: 1.01s\tremaining: 8m 25s\n",
      "100:\ttest: 0.9864416\tbest: 0.9864416 (100)\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "200:\ttest: 0.9872309\tbest: 0.9872309 (200)\ttotal: 3m 59s\tremaining: 5m 55s\n",
      "300:\ttest: 0.9874609\tbest: 0.9874624 (299)\ttotal: 5m 55s\tremaining: 3m 55s\n",
      "400:\ttest: 0.9878224\tbest: 0.9878224 (400)\ttotal: 7m 53s\tremaining: 1m 56s\n",
      "499:\ttest: 0.9882307\tbest: 0.9882307 (499)\ttotal: 9m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9882306587\n",
      "bestIteration = 499\n",
      "\n",
      "cat验证的auc:0.9882306586508337\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(data_X, data_y)):\r\n",
    "    X_fold_train, X_fold_val = data_X.iloc[train_index], data_X.iloc[val_index]\r\n",
    "    y_fold_train, y_fold_val = data_y.iloc[train_index], data_y.iloc[val_index]\r\n",
    "    print(\"fold:\", fold)\r\n",
    "    clf = cv_cat_model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val),\r\n",
    "                           verbose=True, cat_features=categorical_fea)\r\n",
    "    clfs.append(clf)\r\n",
    "\r\n",
    "    pred_fold_val = clfs[fold].predict(X_fold_val, prediction_type='Probability')[:,-1]\r\n",
    "    # print('pred_fold_val:',pred_fold_val)\r\n",
    "    print('cat验证的auc:{}'.format(roc_auc_score(y_fold_val, pred_fold_val)))\r\n",
    "    mean_score += roc_auc_score(y_fold_val, pred_fold_val) / NFOLD\r\n",
    "\r\n",
    "    pred = clfs[fold].predict(data_X_testA, prediction_type='Probability')[:,-1]\r\n",
    "    answers.append(pred)\r\n",
    "\r\n",
    "    pred_eval = clfs[fold].predict(data_X_eval, prediction_type='Probability')[:,-1]\r\n",
    "    answers_eval.append(pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean valAuc:0.9876158967187034\n"
     ]
    }
   ],
   "source": [
    "print('mean valAuc:{}'.format(mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796625\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_eval, (sum(answers_eval)/NFOLD > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248095193902123"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_eval, sum(answers_eval)/NFOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#最终加权平均的预测结果\r\n",
    "cat_pre=sum(answers)/NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./work/cv_catboost/cv_catboost.pkl', 'wb') as file:\r\n",
    "    pickle.dump(ck_cat_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id' : X_testA.index, 'isDefault' : cat_pre})\r\n",
    "# submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x > 0 else 0)\r\n",
    "# submission['isDefault'] = submission['isDefault'].apply(lambda x : x if x < 1 else 1)\r\n",
    "submission.to_csv('./work/cv_catboost/submission_cv_catboost220211210_4.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names_</th>\n",
       "      <th>feature_importances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subGrade</td>\n",
       "      <td>12.635970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>issueDate_diff</td>\n",
       "      <td>7.985715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interestRate</td>\n",
       "      <td>7.704567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term</td>\n",
       "      <td>6.333897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>employmentTitle</td>\n",
       "      <td>5.233110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeOwnership</td>\n",
       "      <td>4.090816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>revolBal</td>\n",
       "      <td>4.086887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dti</td>\n",
       "      <td>4.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>annualIncome</td>\n",
       "      <td>3.886682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grade</td>\n",
       "      <td>3.727884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loanAmnt</td>\n",
       "      <td>3.158751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>issueDate_year</td>\n",
       "      <td>2.742344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>installment</td>\n",
       "      <td>2.632052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ficoRangeLow</td>\n",
       "      <td>2.496062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>revolUtil</td>\n",
       "      <td>2.279620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>n14</td>\n",
       "      <td>2.142826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>postCode</td>\n",
       "      <td>2.091904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ficoRangeHigh</td>\n",
       "      <td>1.827375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>earliesCreditLine_diff</td>\n",
       "      <td>1.816923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>regionCode</td>\n",
       "      <td>1.632171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>totalAcc</td>\n",
       "      <td>1.517993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>n9</td>\n",
       "      <td>1.243864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>n3</td>\n",
       "      <td>1.204373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>n6</td>\n",
       "      <td>1.194497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>employmentLength</td>\n",
       "      <td>1.126588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>purpose</td>\n",
       "      <td>1.104053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>earliesCreditLine_year</td>\n",
       "      <td>0.956694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>n2</td>\n",
       "      <td>0.855789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>title</td>\n",
       "      <td>0.835575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>n8</td>\n",
       "      <td>0.780093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>verificationStatus</td>\n",
       "      <td>0.750459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>delinquency_2years</td>\n",
       "      <td>0.702069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>n5</td>\n",
       "      <td>0.655393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>n0</td>\n",
       "      <td>0.517738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>n1</td>\n",
       "      <td>0.492792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>openAcc</td>\n",
       "      <td>0.492123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>issueDate_month</td>\n",
       "      <td>0.484946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>n7</td>\n",
       "      <td>0.438766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>applicationType</td>\n",
       "      <td>0.371248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pubRec</td>\n",
       "      <td>0.360294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pubRecBankruptcies</td>\n",
       "      <td>0.344137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n4</td>\n",
       "      <td>0.341016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>n10</td>\n",
       "      <td>0.274158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>earliesCreditLine_month</td>\n",
       "      <td>0.179621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>n13</td>\n",
       "      <td>0.137103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>initialListStatus</td>\n",
       "      <td>0.090794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>n12</td>\n",
       "      <td>0.036921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>n11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>policyCode</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature_names_  feature_importances_\n",
       "5                  subGrade             12.635970\n",
       "45           issueDate_diff              7.985715\n",
       "2              interestRate              7.704567\n",
       "1                      term              6.333897\n",
       "6           employmentTitle              5.233110\n",
       "8             homeOwnership              4.090816\n",
       "21                 revolBal              4.086887\n",
       "14                      dti              4.005348\n",
       "9              annualIncome              3.886682\n",
       "4                     grade              3.727884\n",
       "0                  loanAmnt              3.158751\n",
       "43           issueDate_year              2.742344\n",
       "3               installment              2.632052\n",
       "16             ficoRangeLow              2.496062\n",
       "22                revolUtil              2.279620\n",
       "42                      n14              2.142826\n",
       "12                 postCode              2.091904\n",
       "17            ficoRangeHigh              1.827375\n",
       "48   earliesCreditLine_diff              1.816923\n",
       "13               regionCode              1.632171\n",
       "23                 totalAcc              1.517993\n",
       "37                       n9              1.243864\n",
       "31                       n3              1.204373\n",
       "34                       n6              1.194497\n",
       "7          employmentLength              1.126588\n",
       "11                  purpose              1.104053\n",
       "46   earliesCreditLine_year              0.956694\n",
       "30                       n2              0.855789\n",
       "26                    title              0.835575\n",
       "36                       n8              0.780093\n",
       "10       verificationStatus              0.750459\n",
       "15       delinquency_2years              0.702069\n",
       "33                       n5              0.655393\n",
       "28                       n0              0.517738\n",
       "29                       n1              0.492792\n",
       "18                  openAcc              0.492123\n",
       "44          issueDate_month              0.484946\n",
       "35                       n7              0.438766\n",
       "25          applicationType              0.371248\n",
       "19                   pubRec              0.360294\n",
       "20       pubRecBankruptcies              0.344137\n",
       "32                       n4              0.341016\n",
       "38                      n10              0.274158\n",
       "47  earliesCreditLine_month              0.179621\n",
       "41                      n13              0.137103\n",
       "24        initialListStatus              0.090794\n",
       "40                      n12              0.036921\n",
       "39                      n11              0.000000\n",
       "27               policyCode              0.000000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检查重要特征\r\n",
    "pd.DataFrame({'feature_names_' :clfs[1].feature_names_, 'feature_importances_': clfs[1].feature_importances_}).sort_values(by='feature_importances_', ascending=False)\r\n",
    "\r\n",
    "# clfs[0].get_best_score(), clfs[2].get_best_score(), clfs[3].get_best_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
